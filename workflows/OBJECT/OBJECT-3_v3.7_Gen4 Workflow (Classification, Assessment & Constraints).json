{
  "name": "OBJECT-3_v3.7_Gen4 Workflow (Classification, Assessment & Constraints)",
  "nodes": [
    {
      "parameters": {},
      "type": "n8n-nodes-base.manualTrigger",
      "typeVersion": 1,
      "position": [
        -1248,
        0
      ],
      "id": "f93ec061-c5f3-46b5-8feb-51df766d3959",
      "name": "When clicking ‚ÄòExecute workflow‚Äô"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://8b9cbf46.databases.neo4j.io/db/neo4j/query/v2",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.neo4j_payload }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -800,
        0
      ],
      "id": "e6100a10-3f64-48be-96e6-e287f9f86607",
      "name": "Fetch FATObjects",
      "credentials": {
        "httpBasicAuth": {
          "id": "HximmqteOLptnTyu",
          "name": "Neo4j Gen 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse Neo4j response with v3.7 dense_view structure\n// Handles both raw_evidence and enriched_context from OBJECT-2\n// Version: v3.7.0\n\nconst response = $input.first().json;\n\nconst fields = response.data.fields;\nconst values = response.data.values;\n\nconst results = [];\n\nfor (const row of values) {\n  // Map fields to values\n  const obj = {};\n  fields.forEach((field, idx) => {\n    obj[field] = row[idx];\n  });\n  \n  // Parse dense_view from JSON string\n  let denseViewParsed = {};\n  if (typeof obj.dense_view === 'string') {\n    try {\n      denseViewParsed = JSON.parse(obj.dense_view);\n    } catch (e) {\n      console.log(`‚ö†Ô∏è Failed to parse dense_view for ${obj.asset_id}`);\n      denseViewParsed = {};\n    }\n  } else if (typeof obj.dense_view === 'object' && obj.dense_view !== null) {\n    denseViewParsed = obj.dense_view;\n  }\n  \n  const dv = denseViewParsed;\n  \n  // ============================================================\n  // EXTRACT raw_evidence (from OBJECT-2)\n  // ============================================================\n  const rawEvidence = dv.raw_evidence || {};\n  const publications = rawEvidence.publications || [];\n  const grants = rawEvidence.grants || [];\n  const biography = rawEvidence.biography || dv.biography || '';\n  const researchInterests = rawEvidence.research_interests || dv.research_interests || [];\n  \n  // ============================================================\n  // EXTRACT enriched_context (from OBJECT-2 LLM enrichment)\n  // ============================================================\n  const enrichedContext = dv.enriched_context || {};\n  const careerStage = enrichedContext.career_stage || dv.career_stage || 'unknown';\n  const researchDomains = enrichedContext.research_domains || dv.research_domains || [];\n  const methodologies = enrichedContext.methodologies || dv.core_methodologies || dv.methodologies || [];\n  const themes = enrichedContext.themes || dv.research_themes || [];\n  const keywords = enrichedContext.keywords || dv.keywords || [];\n  \n  // ============================================================\n  // DATA QUALITY CHECK (v3.7 requirement)\n  // ============================================================\n  const missingFields = [];\n  if (publications.length === 0) missingFields.push('publications');\n  if (grants.length === 0) missingFields.push('grants');\n  if (!biography || biography.length < 50) missingFields.push('biography');\n  if (researchInterests.length === 0) missingFields.push('research_interests');\n  \n  const hasDataQualityIssue = missingFields.length > 0;\n  const dataQualityPenalty = hasDataQualityIssue ? 0.10 : 0;\n  \n  if (hasDataQualityIssue) {\n    console.log(`‚ö†Ô∏è Data quality warning for ${obj.name}: Missing ${missingFields.join(', ')}`);\n  }\n  \n  // ============================================================\n  // BUILD RICH dense_view_text FOR LLM (v3.7 format)\n  // ============================================================\n  \n  // Format publications for prompt (top 10)\n  const pubText = publications.slice(0, 10).map((p, i) => {\n    const title = p.title || 'Untitled';\n    const abstract = p.abstract ? ` - ${p.abstract.slice(0, 150)}...` : '';\n    const kw = (p.keywords || []).join(', ');\n    return `  ${i+1}. ${title}${abstract}${kw ? ` [${kw}]` : ''}`;\n  }).join('\\n');\n  \n  // Format grants for prompt\n  const grantText = grants.slice(0, 10).map((g, i) => {\n    const title = g.title || 'Untitled Grant';\n    const funder = g.funder ? ` (${g.funder})` : '';\n    const amount = g.amount ? ` - $${Number(g.amount).toLocaleString()}` : '';\n    const dates = g.dates ? ` [${g.dates}]` : '';\n    return `  ${i+1}. ${title}${funder}${amount}${dates}`;\n  }).join('\\n');\n  \n  const denseViewText = `\n============================================================\nRESEARCHER PROFILE\n============================================================\n\nName: ${dv.name || obj.name}\nInstitution: ${dv.institution || obj.institution || 'Unknown'}\nORCID: ${dv.orcid || obj.orcid || 'Not available'}\nCareer Stage: ${careerStage}\n\n------------------------------------------------------------\nRAW EVIDENCE (from source data)\n------------------------------------------------------------\n\nBIOGRAPHY:\n${biography || 'No biography available'}\n\nRESEARCH INTERESTS:\n${researchInterests.length > 0 ? researchInterests.join(', ') : 'Not specified'}\n\nPUBLICATIONS (Top ${Math.min(publications.length, 10)} of ${publications.length}):\n${pubText || '  No publications available'}\n\nGRANTS:\n${grantText || '  No grants available'}\n\n------------------------------------------------------------\nENRICHED CONTEXT (from LLM analysis)\n------------------------------------------------------------\n\nResearch Domains: ${researchDomains.join(', ') || 'Not extracted'}\n\nCore Methodologies: ${methodologies.join(', ') || 'Not extracted'}\n\nResearch Themes: ${themes.join(', ') || 'Not extracted'}\n\nKeywords: ${keywords.join(', ') || 'Not extracted'}\n\n------------------------------------------------------------\nMETRICS\n------------------------------------------------------------\n\nH-index: ${dv.h_index || dv.achievement_scale?.h_index || 0}\nTotal Citations: ${dv.total_citations || 0}\nPublication Count: ${dv.publication_count || publications.length || 0}\nPatent Count: ${dv.patent_count || 0}\nResearch Impact: ${dv.research_impact || dv.achievement_indicators?.research_impact || 'Unknown'}\nCollaboration Breadth: ${dv.collaboration_breadth || dv.achievement_indicators?.collaboration_breadth || 'Unknown'}\n`.trim();\n\n  const qdrantScrollRequest = {\n    filter: {\n      must: [{\n        key: \"asset_id\",\n        match: { value: obj.asset_id }\n      }]\n    },\n    limit: 1,\n    with_payload: true,\n    with_vector: true\n  };\n\n  results.push({\n    json: {\n      asset_id: obj.asset_id,\n      name: obj.name,\n      orcid: obj.orcid,\n      institution: obj.institution,\n      data_completeness: obj.data_completeness,\n      status: obj.status,\n      version: obj.version,\n      fabricated_at: obj.fabricated_at,\n      dense_view_parsed: denseViewParsed,\n      dense_view_text: denseViewText,\n      raw_evidence: {\n        publications: publications,\n        grants: grants,\n        biography: biography,\n        research_interests: researchInterests\n      },\n      enriched_context: enrichedContext,\n      career_stage: careerStage,\n      research_domains: researchDomains,\n      methodologies: methodologies,\n      research_themes: themes,\n      data_quality: {\n        has_issue: hasDataQualityIssue,\n        missing_fields: missingFields,\n        confidence_penalty: dataQualityPenalty\n      },\n      qdrant_scroll_request: qdrantScrollRequest\n    }\n  });\n}\n\nreturn results;"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -608,
        0
      ],
      "id": "2f36ed24-f953-456d-9df3-d1f34ada326f",
      "name": "Parse Neo4j Response"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://3d3d355d-350c-4fd3-a844-17ca2599c7c0.europe-west3-0.gcp.cloud.qdrant.io/collections/objects_researchers_v1/points/scroll",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "qdrantRestApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ { \"filter\": { \"must\": [ { \"key\": \"asset_id\", \"match\": { \"value\": $json.asset_id } } ] }, \"limit\": 1, \"with_payload\": true, \"with_vector\": true } }}",
        "options": {
          "response": {
            "response": {
              "responseFormat": "json"
            }
          }
        }
      },
      "id": "5a5f5c89-fdc0-47f9-bdc5-2b2c582735be",
      "name": "Fetch Embedding Vector",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        1248,
        0
      ],
      "credentials": {
        "openRouterApi": {
          "id": "1srwGILgkvMmHRRn",
          "name": "OpenRouter account"
        },
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// Node: Merge Embedding\n// Version: v3.7.0\n// Purpose: Merge Qdrant embedding vector with researcher data from earlier nodes\n// ============================================================\n\nconst qdrantResponse = $input.first().json;\n\n// ============================================================\n// GET DATA FROM PREVIOUS NODE (Handle Sparse Data or Parse Neo4j Response)\n// This contains dense_view_text, raw_evidence, etc.\n// ============================================================\nlet previousData = {};\n\n// Try to get from Handle Sparse Data first\ntry {\n  previousData = $('Handle Sparse Data').first().json;\n} catch (e) {\n  // Fallback to Parse Neo4j Response\n  try {\n    previousData = $('Parse Neo4j Response').first().json;\n  } catch (e2) {\n    console.log('‚ö†Ô∏è Could not find previous node data');\n  }\n}\n\n// ============================================================\n// PARSE QDRANT RESPONSE\n// ============================================================\nconst responseData = Array.isArray(qdrantResponse) ? qdrantResponse[0] : qdrantResponse;\nconst points = responseData.result?.points || [];\n\nif (points.length === 0) {\n  throw new Error('No points found in Qdrant response');\n}\n\nconst point = points[0];\nconst embeddingVector = point.vector;\nconst payload = point.payload;\n\nif (!embeddingVector || !Array.isArray(embeddingVector)) {\n  throw new Error('Vector not returned or invalid format');\n}\n\nif (!payload || !payload.asset_id) {\n  throw new Error('Payload missing or invalid');\n}\n\n// ============================================================\n// MERGE: Combine Qdrant data with previous node data\n// Priority: previousData > payload (for text fields)\n// ============================================================\nconst mergedData = {\n  // Core identifiers\n  asset_id: payload.asset_id,\n  qdrant_point_id: point.id,\n  \n  // Researcher info (prefer previous node data)\n  name: previousData.name || payload.name,\n  orcid: previousData.orcid || payload.orcid,\n  institution: previousData.institution || payload.institution,\n  \n  // ============================================================\n  // CRITICAL: dense_view_text from previous node (NOT Qdrant)\n  // ============================================================\n  dense_view_text: previousData.dense_view_text || '',\n  dense_view_parsed: previousData.dense_view_parsed || {},\n  \n  // ============================================================\n  // v3.7: raw_evidence and enriched_context from previous node\n  // ============================================================\n  raw_evidence: previousData.raw_evidence || {},\n  enriched_context: previousData.enriched_context || {},\n  \n  // Research profile (merge both sources)\n  career_stage: previousData.career_stage || payload.career_stage || 'unknown',\n  research_domains: previousData.research_domains || payload.research_domains || [],\n  methodologies: previousData.methodologies || payload.methodologies || [],\n  research_themes: previousData.research_themes || payload.research_themes || [],\n  \n  // Metrics (prefer Qdrant payload as it may be more accurate)\n  h_index: payload.h_index || previousData.h_index || 0,\n  total_citations: payload.total_citations || previousData.total_citations || 0,\n  publication_count: payload.publication_count || previousData.publication_count || 0,\n  patent_count: payload.patent_count || previousData.patent_count || 0,\n  research_impact: payload.research_impact || previousData.research_impact || 'Unknown',\n  \n  // The embedding vector (3072 dimensions)\n  embedding_vector: embeddingVector,\n  embedding_dimensions: embeddingVector.length,\n  \n  // Data quality from previous node\n  data_quality: previousData.data_quality || {},\n  data_completeness: payload.data_completeness || previousData.data_completeness || 0,\n  \n  // Status\n  status: payload.status || previousData.status,\n  fabricated_at: payload.fabricated_at || previousData.fabricated_at\n};\n\n// ============================================================\n// VALIDATION: Ensure dense_view_text is not empty\n// ============================================================\nif (!mergedData.dense_view_text || mergedData.dense_view_text.trim().length === 0) {\n  console.log('‚ö†Ô∏è WARNING: dense_view_text is empty!');\n  console.log('   previousData keys:', Object.keys(previousData));\n  console.log('   payload keys:', Object.keys(payload));\n  \n  // Build fallback dense_view_text from available data\n  const fallbackText = `\nResearcher: ${mergedData.name}\nInstitution: ${mergedData.institution}\nCareer Stage: ${mergedData.career_stage}\nResearch Domains: ${mergedData.research_domains.join(', ')}\nMethodologies: ${mergedData.methodologies.join(', ')}\nResearch Themes: ${mergedData.research_themes.join(', ')}\nH-index: ${mergedData.h_index}\n  `.trim();\n  \n  mergedData.dense_view_text = fallbackText;\n  console.log('   Created fallback dense_view_text');\n}\n\nconsole.log(`‚úÖ Merge Embedding: ${mergedData.name}`);\nconsole.log(`   Embedding dimensions: ${mergedData.embedding_dimensions}`);\nconsole.log(`   dense_view_text length: ${mergedData.dense_view_text.length} chars`);\nconsole.log(`   raw_evidence.publications: ${(mergedData.raw_evidence.publications || []).length}`);\n\nreturn [{\n  json: mergedData\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1456,
        0
      ],
      "id": "41d6fb3f-8ee7-45e2-ac1d-cbd6b71078d0",
      "name": "Merge Embedding"
    },
    {
      "parameters": {
        "jsCode": "const cypherPayload = {\n  statement: `\n    MATCH (fat:FATObject)\n    WHERE fat.asset_id = 'fat:researcher:colin_barrow'\n      AND fat.status = 'fabricated'\n    RETURN \n        fat.asset_id AS asset_id,\n        fat.name AS name,\n        fat.orcid AS orcid,\n        fat.institution AS institution,\n        fat.dense_view AS dense_view,\n        fat.data_completeness AS data_completeness,\n        fat.status AS status,\n        fat.version AS version,\n        fat.fabricated_at AS fabricated_at\n  `,\n  parameters: {}\n};\n\nreturn [{\n  json: {\n    neo4j_payload: cypherPayload\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1776,
        1504
      ],
      "id": "42dfe35b-3348-4632-a75e-24fd41e3cb81",
      "name": "Prepare Fetch FATObjects(Colin)"
    },
    {
      "parameters": {
        "promptType": "define",
        "text": "={{ $json.user_prompt }}",
        "messages": {
          "messageValues": [
            {
              "message": "Assign 3-10 codes that comprehensively represent the researcher's expertise. Adjust count based on career complexity: - Early-career/narrow focus: 3-5 codes - Mid-career/multi-domain: 5-7 codes   - Senior/interdisciplinary: 7-10 codes Only assign codes where you have high confidence (0.70+)"
            }
          ]
        },
        "batching": {}
      },
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "typeVersion": 1.7,
      "position": [
        1616,
        288
      ],
      "id": "9a1948e3-0da3-454d-82fe-fd93adcf95c4",
      "name": "Pass 2: LLM Enrichment"
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// Node: Parse LLM Response (with Retry Support)\n// Extracts BOTH Standard A (ANZSRC) and Standard B (OECD FOS) classifications\n// Added: Error handling with retry flag\n// ============================================================\n\nconst llmResponse = $input.first().json;\nconst promptData = $('Prepare Dual-Standard LLM Prompt').first().json;\n\n// Track retry attempts\nconst currentRetryCount = promptData.llm_retry_count || 0;\nconst MAX_RETRIES = 2;\n\n// Extract content from LLM response\nlet content;\n\ntry {\n  if (llmResponse.choices?.[0]?.message?.content) {\n    content = llmResponse.choices[0].message.content;\n  } else if (llmResponse.text) {\n    content = llmResponse.text;\n  } else if (llmResponse.output) {\n    content = llmResponse.output;\n  } else if (Array.isArray(llmResponse) && llmResponse[0]?.text) {\n    content = llmResponse[0].text;\n  } else {\n    throw new Error(`Unexpected LLM response structure: ${JSON.stringify(llmResponse).slice(0, 200)}`);\n  }\n\n  if (!content) {\n    throw new Error('No content in LLM response');\n  }\n\n  // Parse JSON from response\n  let parsed;\n  let cleanContent = content.trim();\n  \n  // Remove markdown code blocks if present\n  if (cleanContent.startsWith('```json')) {\n    cleanContent = cleanContent.slice(7);\n  } else if (cleanContent.startsWith('```')) {\n    cleanContent = cleanContent.slice(3);\n  }\n  if (cleanContent.endsWith('```')) {\n    cleanContent = cleanContent.slice(0, -3);\n  }\n  \n  parsed = JSON.parse(cleanContent.trim());\n\n  // Validate structure\n  if (!parsed.standard_a?.classifications) {\n    throw new Error('LLM response missing standard_a.classifications');\n  }\n\n  const CONFIDENCE_THRESHOLD = 0.70;\n\n  // Process Standard A (ANZSRC)\n  const standardAClassifications = (parsed.standard_a.classifications || [])\n    .filter(c => c.confidence >= CONFIDENCE_THRESHOLD)\n    .map(c => ({\n      code: String(c.code),\n      name: c.name || 'Unknown',\n      confidence: Math.min(1.0, Math.max(0.0, c.confidence)),\n      justification: c.justification || '',\n      evidence: c.evidence || []\n    }))\n    .sort((a, b) => b.confidence - a.confidence);\n\n  // Process Standard B (OECD FOS)\n  const standardBClassifications = (parsed.standard_b?.classifications || [])\n    .filter(c => c.confidence >= CONFIDENCE_THRESHOLD)\n    .map(c => ({\n      code: String(c.code),\n      name: c.name || 'Unknown',\n      confidence: Math.min(1.0, Math.max(0.0, c.confidence)),\n      justification: c.justification || ''\n    }))\n    .sort((a, b) => b.confidence - a.confidence);\n\n  console.log(`‚úÖ Standard A: ${standardAClassifications.length} codes`);\n  console.log(`‚úÖ Standard B: ${standardBClassifications.length} codes`);\n\n  return [{\n    json: {\n      // Core identifiers\n      asset_id: promptData.asset_id,\n      name: promptData.name,\n      orcid: promptData.orcid,\n      institution: promptData.institution,\n      qdrant_point_id: promptData.qdrant_point_id,\n      \n      // Parse success\n      parse_success: true,\n      needs_retry: false,\n      \n      // Standard A classifications\n      classifications: standardAClassifications,\n      classification_count: standardAClassifications.length,\n      \n      // Standard B classifications\n      standard_b_classifications: standardBClassifications,\n      standard_b_count: standardBClassifications.length,\n      \n      // Reasoning\n      reasoning: parsed.reasoning || '',\n      \n      // LLM metadata\n      model: llmResponse.model || 'openai/gpt-4o',\n      llm_retry_count: currentRetryCount\n    }\n  }];\n\n} catch (parseError) {\n  // JSON parsing failed - check if we can retry\n  console.log(`‚ö†Ô∏è LLM Parse Error for ${promptData.name}: ${parseError.message}`);\n  console.log(`   Retry count: ${currentRetryCount}/${MAX_RETRIES}`);\n  \n  if (currentRetryCount < MAX_RETRIES) {\n    // Flag for retry\n    return [{\n      json: {\n        // Pass through all original data for retry\n        ...promptData,\n        \n        // Retry flags\n        parse_success: false,\n        needs_retry: true,\n        llm_retry_count: currentRetryCount + 1,\n        \n        // Error details\n        parse_error: parseError.message,\n        failed_content_preview: content ? content.slice(0, 500) : 'No content',\n        \n        // Will be used by retry logic\n        retry_reason: 'JSON parse failure - truncated or malformed response'\n      }\n    }];\n  } else {\n    // Max retries exceeded - route to failed\n    return [{\n      json: {\n        asset_id: promptData.asset_id,\n        name: promptData.name,\n        orcid: promptData.orcid,\n        institution: promptData.institution,\n        qdrant_point_id: promptData.qdrant_point_id,\n        \n        // Failure flags\n        parse_success: false,\n        needs_retry: false,\n        classification_failed: true,\n        \n        // Error details\n        parse_error: parseError.message,\n        failed_content_preview: content ? content.slice(0, 500) : 'No content',\n        llm_retry_count: currentRetryCount,\n        failure_reason: `Max retries (${MAX_RETRIES}) exceeded - JSON parse failure`\n      }\n    }];\n  }\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1584,
        608
      ],
      "id": "f581cd0f-59a8-4b77-a0cd-ad92d188a6ae",
      "name": "Parse LLM Response"
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// Calculate Final Confidence\n// Version: v3.7.0\n// Gen 4 + v3.7: Includes CRE blocking + data quality penalty\n// ============================================================\n\nconst inputData = $input.first().json;\n\nconst classifications = inputData.classifications || [];\nconst cf1Penalty = inputData.cf1_assessment?.penalty || 0.0;\nconst crosswalkModifier = inputData.crosswalk_assessment?.modifier || 0.0;\nconst creAssessment = inputData.cre_assessment || {};\n\n// ============================================================\n// v3.7: DATA QUALITY PENALTY\n// Per Definition Card v3.7 Section 3:\n// \"If dense_view lacks required fields, OBJECT-3 SHOULD:\n//  1. Emit data_quality_warning signal with missing field list\n//  2. Apply -10% confidence penalty to final score\n//  3. Flag classification for human review regardless of confidence\"\n// ============================================================\nconst dataQuality = inputData.data_quality || {};\nconst dataQualityPenalty = dataQuality.confidence_penalty || 0;\nconst forceHumanReview = dataQuality.has_issue || false;\n\nif (dataQuality.has_issue) {\n  console.log(`‚ö†Ô∏è DATA QUALITY WARNING (v3.7):`);\n  console.log(`   Missing fields: ${(dataQuality.missing_fields || []).join(', ')}`);\n  console.log(`   Applying -${(dataQualityPenalty * 100).toFixed(0)}% confidence penalty`);\n  console.log(`   Flagging for human review: YES`);\n}\n\n// ============================================================\n// GEN 4: CHECK FOR BLOCKING CONSTRAINT FAILURES\n// ============================================================\nif (creAssessment.blocking_failures?.length > 0) {\n  console.log(`üö´ BLOCKED by CRE constraints: ${creAssessment.blocking_failures.join(', ')}`);\n  \n  return [{\n    json: {\n      // Core data\n      asset_id: inputData.asset_id,\n      name: inputData.name,\n      qdrant_point_id: inputData.qdrant_point_id,\n      reasoning: inputData.reasoning,\n      model: inputData.model,\n      \n      // Assessment results\n      cf1_assessment: inputData.cf1_assessment,\n      crosswalk_assessment: inputData.crosswalk_assessment,\n      cre_assessment: inputData.cre_assessment,\n      data_quality: inputData.data_quality,\n      \n      // Classifications (empty due to blocking)\n      classifications: [],\n      classification_count: 0,\n      standard_b_classifications: inputData.standard_b_classifications,\n      standard_b_count: inputData.standard_b_count,\n      \n      // Failure state\n      final_confidence: 0.0,\n      classification_failed: true,\n      classification_blocked: true,\n      force_human_review: true,\n      failure_reason: `Blocked by CRE constraints: ${creAssessment.blocking_failures.join(', ')}`,\n      blocking_constraints: creAssessment.blocking_failures,\n      \n      // Timestamp\n      classified_at: new Date().toISOString()\n    }\n  }];\n}\n\n// ============================================================\n// CHECK FOR EMPTY CLASSIFICATIONS\n// ============================================================\nif (classifications.length === 0) {\n  console.log(`‚ùå No valid classifications after assessment`);\n  \n  return [{\n    json: {\n      // Core data\n      asset_id: inputData.asset_id,\n      name: inputData.name,\n      qdrant_point_id: inputData.qdrant_point_id,\n      reasoning: inputData.reasoning,\n      model: inputData.model,\n      \n      // Assessment results\n      cf1_assessment: inputData.cf1_assessment,\n      crosswalk_assessment: inputData.crosswalk_assessment,\n      cre_assessment: inputData.cre_assessment,\n      data_quality: inputData.data_quality,\n      \n      // Empty classifications\n      classifications: [],\n      classification_count: 0,\n      standard_b_classifications: inputData.standard_b_classifications,\n      standard_b_count: inputData.standard_b_count,\n      \n      // Failure state\n      final_confidence: 0.0,\n      classification_failed: true,\n      classification_blocked: false,\n      force_human_review: true,\n      failure_reason: 'No valid classifications after assessment',\n      \n      // Timestamp\n      classified_at: new Date().toISOString()\n    }\n  }];\n}\n\n// ============================================================\n// CALCULATE CONFIDENCE WITH ALL MODIFIERS\n// Includes: CF1, Crosswalk, CRE, Data Quality (v3.7)\n// ============================================================\nconst crePenalty = creAssessment.cre_penalty || 0.0;\n\n// Apply ALL penalties/modifiers to each classification\nconst adjustedClassifications = classifications.map(c => {\n  // Total adjustment = -cf1 + crosswalk - cre - dataQuality\n  const totalAdjustment = -cf1Penalty + crosswalkModifier - crePenalty - dataQualityPenalty;\n  const adjustedConfidence = Math.max(0.0, Math.min(1.0, c.confidence + totalAdjustment));\n  \n  return {\n    ...c,\n    base_confidence: c.confidence,\n    adjustments: {\n      cf1: -cf1Penalty,\n      crosswalk: crosswalkModifier,\n      cre: -crePenalty,\n      data_quality: -dataQualityPenalty,\n      total: Math.round(totalAdjustment * 10000) / 10000\n    },\n    adjusted_confidence: Math.round(adjustedConfidence * 10000) / 10000\n  };\n});\n\n// Calculate final confidence (mean of adjusted confidences)\nconst confidences = adjustedClassifications.map(c => c.adjusted_confidence);\nconst baseMean = classifications.reduce((a, c) => a + c.confidence, 0) / classifications.length;\nconst finalConfidence = Math.round((confidences.reduce((a, b) => a + b, 0) / confidences.length) * 10000) / 10000;\n\n// ============================================================\n// DETERMINE ROUTING SIGNALS\n// Per researcher_instance_spec_v2.2 Section 8:\n// - Auto-Approve: >= 0.85\n// - Human Review: 0.60-0.85\n// - Rejection: < 0.60\n// ============================================================\nconst FAIL_THRESHOLD = 0.60;\nconst AUTO_APPROVE_THRESHOLD = 0.85;\n\nconst classificationFailed = finalConfidence < FAIL_THRESHOLD;\nconst failureReason = classificationFailed \n  ? `Final confidence ${finalConfidence.toFixed(2)} below threshold ${FAIL_THRESHOLD}`\n  : null;\n\n// v3.7: Force human review if data quality issues exist, regardless of confidence\nconst requiresHumanReview = forceHumanReview || (finalConfidence >= FAIL_THRESHOLD && finalConfidence < AUTO_APPROVE_THRESHOLD);\n\n// Determine routing recommendation (for OBJECT-4)\nlet routingRecommendation = 'REJECT';\nif (!classificationFailed) {\n  if (forceHumanReview) {\n    routingRecommendation = 'HUMAN_REVIEW';\n  } else if (finalConfidence >= AUTO_APPROVE_THRESHOLD) {\n    routingRecommendation = 'AUTO_APPROVE';\n  } else {\n    routingRecommendation = 'HUMAN_REVIEW';\n  }\n}\n\n// ============================================================\n// LOG SUMMARY\n// ============================================================\nconsole.log(`\\n============================================================`);\nconsole.log(`‚úÖ CONFIDENCE CALCULATION COMPLETE`);\nconsole.log(`============================================================`);\nconsole.log(`   Researcher: ${inputData.name}`);\nconsole.log(`   Classifications: ${adjustedClassifications.length} codes`);\nconsole.log(`\\n   CONFIDENCE BREAKDOWN:`);\nconsole.log(`   ‚îú‚îÄ Base mean:           ${baseMean.toFixed(3)}`);\nconsole.log(`   ‚îú‚îÄ CF1 penalty:         ${cf1Penalty > 0 ? '-' : ' '}${(cf1Penalty * 100).toFixed(0)}%`);\nconsole.log(`   ‚îú‚îÄ Crosswalk modifier:  ${crosswalkModifier >= 0 ? '+' : ''}${(crosswalkModifier * 100).toFixed(0)}%`);\nconsole.log(`   ‚îú‚îÄ CRE penalty:         ${crePenalty > 0 ? '-' : ' '}${(crePenalty * 100).toFixed(0)}%`);\nconsole.log(`   ‚îú‚îÄ Data quality penalty:${dataQualityPenalty > 0 ? '-' : ' '}${(dataQualityPenalty * 100).toFixed(0)}%`);\nconsole.log(`   ‚îî‚îÄ FINAL CONFIDENCE:    ${finalConfidence.toFixed(3)}`);\nconsole.log(`\\n   ROUTING:`);\nconsole.log(`   ‚îú‚îÄ Classification failed: ${classificationFailed}`);\nconsole.log(`   ‚îú‚îÄ Force human review:    ${forceHumanReview}`);\nconsole.log(`   ‚îî‚îÄ Recommendation:        ${routingRecommendation}`);\nconsole.log(`============================================================\\n`);\n\n// ============================================================\n// RETURN OUTPUT\n// ============================================================\nreturn [{\n  json: {\n    // Core identifiers\n    asset_id: inputData.asset_id,\n    name: inputData.name,\n    orcid: inputData.orcid,\n    institution: inputData.institution,\n    qdrant_point_id: inputData.qdrant_point_id,\n    \n    // LLM metadata\n    reasoning: inputData.reasoning,\n    model: inputData.model,\n    \n    // Assessment results (pass through)\n    cf1_assessment: inputData.cf1_assessment,\n    crosswalk_assessment: inputData.crosswalk_assessment,\n    cre_assessment: inputData.cre_assessment,\n    data_quality: inputData.data_quality,\n    \n    // Hierarchical search metadata (v3.7)\n    retrieval_sources: inputData.retrieval_sources,\n    matched_groups: inputData.matched_groups,\n    \n    // Standard A classifications with adjustments\n    classifications: adjustedClassifications,\n    classification_count: adjustedClassifications.length,\n    \n    // Standard B classifications (pass through unchanged)\n    standard_b_classifications: inputData.standard_b_classifications,\n    standard_b_count: inputData.standard_b_count,\n    \n    // Final confidence calculation\n    final_confidence: finalConfidence,\n    confidence_breakdown: {\n      base_mean: Math.round(baseMean * 10000) / 10000,\n      cf1_penalty: cf1Penalty,\n      crosswalk_modifier: crosswalkModifier,\n      cre_penalty: crePenalty,\n      data_quality_penalty: dataQualityPenalty,\n      net_adjustment: Math.round((-cf1Penalty + crosswalkModifier - crePenalty - dataQualityPenalty) * 10000) / 10000\n    },\n    \n    // Routing signals (for OBJECT-4)\n    classification_failed: classificationFailed,\n    classification_blocked: false,\n    force_human_review: forceHumanReview,\n    requires_human_review: requiresHumanReview,\n    failure_reason: failureReason,\n    routing_recommendation: routingRecommendation,\n    \n    // Thresholds applied (for audit trail)\n    thresholds_applied: {\n      fail_threshold: FAIL_THRESHOLD,\n      auto_approve_threshold: AUTO_APPROVE_THRESHOLD,\n      min_code_confidence: 0.70\n    },\n    \n    // Timestamp\n    classified_at: new Date().toISOString(),\n    workflow_version: 'OBJECT-3_v3.7.0'\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        944,
        624
      ],
      "id": "dfa7efdc-1f86-4f5b-8499-bcf77a26fc5e",
      "name": "Calculate Final Confidence"
    },
    {
      "parameters": {
        "jsCode": "// Prepare Neo4j Write Query - Dual Standard + CRE Assessment\n// Gen 4: Persists ACTUAL CRE assessment to FATObject node\n\nconst inputData = $input.first().json;\n\n// Handle classification failure\nif (inputData.classification_failed) {\n  const failedCypherPayload = {\n    statement: `\n      MATCH (obj:FATObject {asset_id: $asset_id})\n      SET obj.status = 'classification_failed',\n          obj.classification_failed_at = datetime(),\n          obj.classification_failed_reason = $failure_reason\n      RETURN obj.asset_id AS asset_id, obj.status AS status\n    `,\n    parameters: {\n      asset_id: inputData.asset_id,\n      failure_reason: inputData.failure_reason\n    }\n  };\n  \n  return [{\n    json: {\n      ...inputData,\n      neo4j_payload: failedCypherPayload,\n      is_failure_update: true\n    }\n  }];\n}\n\n// Deduplicate Standard A classifications\nconst seenCodesA = new Set();\nconst uniqueClassificationsA = [];\n\nfor (const c of inputData.classifications) {\n  const codeStr = String(c.code);\n  if (!seenCodesA.has(codeStr)) {\n    seenCodesA.add(codeStr);\n    uniqueClassificationsA.push({\n      code: parseInt(c.code, 10),\n      name: c.name,\n      confidence: c.adjusted_confidence,\n      justification: c.justification,\n      evidence: c.evidence || [],\n      cf1_validated: c.cf1_validated || false\n    });\n  }\n}\n\n// Prepare Standard B classifications\nconst standardBClassifications = (inputData.standard_b_classifications || []).map(c => ({\n  code: String(c.code),\n  name: c.name,\n  confidence: c.confidence,\n  justification: c.justification || ''\n}));\n\n// ============================================================\n// FIX: Get CRE Assessment directly from node by name\n// ============================================================\nconst existingCre = $('Merge CRE Output').first().json.cre_assessment || {};\nconst cf1Assessment = inputData.cf1_assessment || {};\nconst crosswalk = inputData.crosswalk_assessment || {};\n\nconst cf1Result = existingCre.cf1_result || {};\nconst cf5Result = existingCre.cf5_result || {};\n\nconst creAssessment = {\n  cf1_trl: {\n    passed: cf1Result.passed !== false,\n    gate_mode: cf1Result.gate_mode || 'block',\n    inferred_level: cf1Result.inferred_level || null,\n    required_level: cf1Result.required_level || null,\n    confidence: cf1Result.confidence || null,\n    evidence: cf1Result.evidence || [],\n    message: cf1Result.message || ''\n  },\n  cf5_regulatory: {\n    passed: cf5Result.passed !== false,\n    gate_mode: cf5Result.gate_mode || 'block',\n    warnings: cf5Result.warnings || [],\n    checked_domains: cf5Result.checked_domains || [],\n    message: cf5Result.message || ''\n  },\n  anzsrc_hierarchy: {\n    passed: cf1Assessment.passed !== false,\n    violations: cf1Assessment.violations || [],\n    flags: cf1Assessment.flags || [],\n    penalty: cf1Assessment.penalty || 0\n  },\n  crosswalk_assessment: {\n    alignment_score: crosswalk.alignment_score || null,\n    alignment_status: crosswalk.alignment_status || 'unknown',\n    modifier: crosswalk.modifier || 0\n  },\n  blocking_failures: existingCre.blocking_failures || [],\n  penalising_failures: existingCre.penalising_failures || [],\n  requires_hitl: existingCre.requires_hitl || false,\n  cre_penalty: existingCre.cre_penalty || 0,\n  assessed_at: new Date().toISOString(),\n  cre_version: 'Gen4'\n};\n\n// Build Cypher query\nconst cypherPayload = {\n  statement: `\n    MATCH (obj:FATObject {asset_id: $asset_id})\n    SET obj.status = 'classified',\n        obj.classified_at = datetime(),\n        obj.classified_by = $agent_id,\n        obj.final_confidence = $final_confidence,\n        obj.cre_assessment = $cre_assessment\n    \n    WITH obj\n    \n    UNWIND $classifications_a AS cls\n    MATCH (std_a:Standard:FoR {code: cls.code})\n    MERGE (obj)-[r_a:CLASSIFIED_AS]->(std_a)\n    ON CREATE SET \n      r_a.confidence = cls.confidence,\n      r_a.justification = cls.justification,\n      r_a.evidence = cls.evidence,\n      r_a.classified_at = datetime(),\n      r_a.classified_by = $agent_id,\n      r_a.model = $model,\n      r_a.standard_type = 'primary',\n      r_a.taxonomy = 'ANZSRC_FoR_2020',\n      r_a.validated = false,\n      r_a.validation_state = 'PENDING',\n      r_a.cf1_validated = cls.cf1_validated\n    ON MATCH SET\n      r_a.confidence = cls.confidence,\n      r_a.justification = cls.justification,\n      r_a.evidence = cls.evidence,\n      r_a.classified_at = datetime(),\n      r_a.classified_by = $agent_id,\n      r_a.model = $model\n    \n    WITH obj, count(r_a) AS anzsrc_count\n    \n    UNWIND $classifications_b AS cls_b\n    MATCH (std_b:Standard:OECD_FOS {code: cls_b.code})\n    MERGE (obj)-[r_b:CLASSIFIED_AS]->(std_b)\n    ON CREATE SET \n      r_b.confidence = cls_b.confidence,\n      r_b.justification = cls_b.justification,\n      r_b.classified_at = datetime(),\n      r_b.classified_by = $agent_id,\n      r_b.model = $model,\n      r_b.standard_type = 'domain_hub',\n      r_b.taxonomy = 'OECD_FOS_2007',\n      r_b.validated = false,\n      r_b.validation_state = 'PENDING'\n    ON MATCH SET\n      r_b.confidence = cls_b.confidence,\n      r_b.justification = cls_b.justification,\n      r_b.classified_at = datetime(),\n      r_b.classified_by = $agent_id,\n      r_b.model = $model\n    \n    RETURN obj.asset_id AS asset_id, \n           obj.status AS status,\n           anzsrc_count AS standard_a_relationships,\n           count(r_b) AS standard_b_relationships\n  `,\n  parameters: {\n    asset_id: inputData.asset_id,\n    agent_id: 'object3_classifier_v3.6.1',\n    model: inputData.model || 'openai/gpt-4o',\n    final_confidence: inputData.final_confidence,\n    classifications_a: uniqueClassificationsA,\n    classifications_b: standardBClassifications,\n    cre_assessment: JSON.stringify(creAssessment)\n  }\n};\n\nconsole.log(`‚úÖ Neo4j write: ${uniqueClassificationsA.length} ANZSRC + ${standardBClassifications.length} FOS`);\nconsole.log(`‚úÖ CRE: TRL=${creAssessment.cf1_trl.inferred_level}, conf=${creAssessment.cf1_trl.confidence}`);\n\nreturn [{\n  json: {\n    asset_id: inputData.asset_id,\n    name: inputData.name,\n    qdrant_point_id: inputData.qdrant_point_id,\n    classifications: uniqueClassificationsA,\n    classification_count: uniqueClassificationsA.length,\n    standard_b_classifications: standardBClassifications,\n    standard_b_count: standardBClassifications.length,\n    final_confidence: inputData.final_confidence,\n    cf1_assessment: inputData.cf1_assessment,\n    crosswalk_assessment: inputData.crosswalk_assessment,\n    cre_assessment: creAssessment,\n    confidence_breakdown: inputData.confidence_breakdown,\n    reasoning: inputData.reasoning,\n    classified_at: inputData.classified_at,\n    neo4j_payload: cypherPayload,\n    is_failure_update: false\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1168,
        624
      ],
      "id": "2b13e08c-b5c4-4d73-a35f-abd9318dbd7d",
      "name": "Prepare Neo4j Write Query"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://8b9cbf46.databases.neo4j.io/db/neo4j/query/v2",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.neo4j_payload }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -896,
        896
      ],
      "id": "44a803e3-9185-42ea-8002-f9d5d4798b13",
      "name": "Write to Neo4j",
      "credentials": {
        "httpBasicAuth": {
          "id": "HximmqteOLptnTyu",
          "name": "Neo4j Gen 2"
        }
      }
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "https://3d3d355d-350c-4fd3-a844-17ca2599c7c0.europe-west3-0.gcp.cloud.qdrant.io/collections/objects_researchers_v1/points/payload",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "qdrantRestApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.qdrant_payload }}",
        "options": {
          "allowUnauthorizedCerts": true
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -368,
        896
      ],
      "id": "bad79b10-b397-46d7-b387-8b8b38cb981b",
      "name": "Update Qdrant",
      "credentials": {
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Final Output - Dual Standard Summary + Signal Confirmation\n// Gen 4 + v3.7.2: References CRE assessment and signal emission\n// Version: v3.7.2 - Fixed signal reference\n\n// ============================================================\n// GET DATA FROM UPSTREAM NODES\n// ============================================================\nconst inputData = $('Prepare Qdrant Payload').first().json;\nconst neo4jResult = $('Write to Neo4j').first().json;\nconst qdrantResult = $('Update Qdrant').first().json;\nconst postgresResult = $('Store Crosswalk Metadata').first().json;\n\n// FIXED: Get signal data from Prepare Classification Signals node (not HTTP response)\nconst signalData = $('Prepare Classification Signals').first().json;\nconst signalsEmitted = signalData.signals_emitted || [];\nconst signalCount = signalData.signal_count || 0;\n\n// Direct reference to CRE assessment from source node\nconst creAssessment = $('Merge CRE Output').first().json.cre_assessment || null;\n\n// Parse Neo4j response for relationship counts\nconst neo4jValues = neo4jResult?.data?.values?.[0] || [];\nconst standardARelationships = neo4jValues[2] || 0;\nconst standardBRelationships = neo4jValues[3] || 0;\n\n// Get crosswalk status\nconst crosswalkStatus = inputData.crosswalk_assessment?.alignment_status \n  || (inputData.crosswalk_assessment?.alignment_score === null \n      ? \"no_crosswalks\" \n      : inputData.crosswalk_assessment?.alignment_score >= 0.50 \n        ? \"aligned\" \n        : inputData.crosswalk_assessment?.alignment_score >= 0.30\n          ? \"acceptable\"\n          : \"misaligned\");\n\nconst output = {\n  // === Classification Result ===\n  asset_id: inputData.asset_id,\n  name: inputData.name,\n  status: \"classified\",\n  \n  // === Standard A Classifications (ANZSRC) ===\n  standard_a: {\n    taxonomy: \"ANZSRC_FoR_2020\",\n    role: \"primary_classification\",\n    classifications: inputData.classifications.map(c => ({\n      code: c.code,\n      name: c.name,\n      confidence: c.adjusted_confidence || c.confidence,\n      justification: c.justification,\n      evidence: c.evidence || []\n    })),\n    count: inputData.classification_count\n  },\n  \n  // === Standard B Classifications (OECD FOS) ===\n  standard_b: {\n    taxonomy: \"OECD_FOS_2007\",\n    role: \"domain_hub\",\n    classifications: (inputData.standard_b_classifications || []).map(c => ({\n      code: c.code,\n      name: c.name,\n      confidence: c.confidence,\n      justification: c.justification\n    })),\n    count: inputData.standard_b_count || 0\n  },\n  \n  // === Confidence & Assessment ===\n  assessment: {\n    final_confidence: inputData.final_confidence,\n    confidence_breakdown: inputData.confidence_breakdown,\n    \n    // ANZSRC Hierarchy Check\n    anzsrc_hierarchy: {\n      passed: inputData.cf1_assessment?.passed || false,\n      violations: inputData.cf1_assessment?.violations?.length || 0,\n      flags: inputData.cf1_assessment?.flags?.length || 0,\n      penalty: inputData.cf1_assessment?.penalty || 0\n    },\n    \n    // Crosswalk Assessment\n    crosswalk: {\n      alignment_score: inputData.crosswalk_assessment?.alignment_score || null,\n      modifier: inputData.crosswalk_assessment?.modifier || 0,\n      mappings_checked: inputData.crosswalk_assessment?.total_mappings_checked || 0,\n      status: crosswalkStatus\n    },\n    \n    // === GEN 4: CRE ASSESSMENT (Direct Reference) ===\n    cre: creAssessment ? {\n      skipped: creAssessment.skipped || false,\n      cf1_trl: creAssessment.cf1_result || null,\n      cf5_regulatory: creAssessment.cf5_result || null,\n      blocking_failures: creAssessment.blocking_failures || [],\n      penalising_failures: creAssessment.penalising_failures || [],\n      cre_penalty: creAssessment.cre_penalty || 0,\n      requires_hitl: creAssessment.requires_hitl || false\n    } : null\n  },\n  \n  // === Reasoning ===\n  reasoning: inputData.reasoning,\n  \n  // === OBJECT-4 Routing Preview ===\n  routing: {\n    recommendation: inputData.final_confidence >= 0.85 \n      ? \"AUTO_APPROVE\" \n      : inputData.final_confidence >= 0.60 \n        ? \"HUMAN_REVIEW\" \n        : \"REJECT\",\n    confidence_threshold: inputData.final_confidence >= 0.85 \n      ? \">=0.85\" \n      : inputData.final_confidence >= 0.60 \n        ? \"0.60-0.85\" \n        : \"<0.60\",\n    requires_validation: inputData.final_confidence < 0.85,\n    blocked_by_cre: creAssessment?.blocking_failures?.length > 0 || false\n  },\n  \n  // === Storage Confirmation ===\n  storage: {\n    neo4j: {\n      status: \"success\",\n      standard_a_relationships: standardARelationships,\n      standard_b_relationships: standardBRelationships,\n      total_relationships: standardARelationships + standardBRelationships\n    },\n    qdrant: {\n      status: qdrantResult?.status || \"ok\",\n      point_id: inputData.qdrant_point_id\n    },\n    postgresql: {\n      status: postgresResult?.id ? \"success\" : \"ok\",\n      job_id: postgresResult?.job_id || null,\n      record_id: postgresResult?.id || null\n    }\n  },\n  \n  // === v3.7.2: SIGNALS EMITTED (Fixed reference) ===\n  signals: {\n    count: signalCount,\n    types: signalsEmitted.map(s => s.signal_type),\n    written_to_neo4j: true,\n    details: signalsEmitted.map(s => ({\n      type: s.signal_type,\n      category: s.category,\n      value: s.value\n    }))\n  },\n  \n  // === Metadata ===\n  metadata: {\n    classified_at: inputData.classified_at,\n    classified_by: \"object3_classifier_v3.7.2\",\n    model: inputData.model || \"open-oss-120b\",\n    workflow_version: \"OBJECT-3_v3.7.2_Gen4_Signals\"\n  }\n};\n\n// ============================================================\n// LOG SUMMARY\n// ============================================================\nconsole.log(`\\n============================================================`);\nconsole.log(`‚úÖ CLASSIFICATION COMPLETE: ${output.name}`);\nconsole.log(`============================================================`);\nconsole.log(`   Standard A: ${output.standard_a.count} codes (ANZSRC FoR 2020)`);\nconsole.log(`   Standard B: ${output.standard_b.count} codes (OECD FOS 2007)`);\nconsole.log(`   Final Confidence: ${output.assessment.final_confidence}`);\nconsole.log(`   Routing: ${output.routing.recommendation}`);\nconsole.log(`   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ`);\nconsole.log(`   CRE CF1 (TRL): ${creAssessment?.cf1_result?.passed ? 'PASSED' : 'N/A'} (Level ${creAssessment?.cf1_result?.inferred_level || 'N/A'})`);\nconsole.log(`   CRE CF5 (Regulatory): ${creAssessment?.cf5_result?.passed ? 'PASSED' : 'N/A'}`);\nconsole.log(`   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ`);\nconsole.log(`   üì° Signals: ${signalCount} emitted ‚Üí Neo4j`);\nsignalsEmitted.forEach(s => {\n  const icon = s.category === 'SystemSignal' ? '‚ö†Ô∏è' : '‚úÖ';\n  console.log(`      ${icon} ${s.signal_type}`);\n});\nconsole.log(`============================================================\\n`);\n\nreturn [{\n  json: output\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        768,
        896
      ],
      "id": "1edbeb93-d1c5-40e5-815b-989e340a7835",
      "name": "Final Output"
    },
    {
      "parameters": {
        "jsCode": "// Prepare Qdrant Payload - Dual Standard\n// Updates payload with BOTH Standard A and Standard B classification metadata\n\nconst inputData = $('Prepare Neo4j Write Query').first().json;\n\n// Get existing payload from Merge Embedding (preserves all researcher data)\nconst existingPayload = $('Merge Embedding').first().json;\n\n// Extract Standard A classification codes as integers\nconst classificationCodesA = inputData.classifications.map(c => parseInt(c.code, 10));\nconst classificationConfidencesA = inputData.classifications.map(c => c.confidence);\n\n// Extract Standard B classification codes as strings\nconst classificationCodesB = (inputData.standard_b_classifications || []).map(c => c.code);\nconst classificationConfidencesB = (inputData.standard_b_classifications || []).map(c => c.confidence);\n\n// Build merged payload - preserve ALL existing fields, add classification fields\nconst mergedPayload = {\n  // Existing researcher data (preserve everything)\n  asset_id: existingPayload.asset_id,\n  object_type: \"researcher\",\n  name: existingPayload.name,\n  institution: existingPayload.institution,\n  orcid: existingPayload.orcid,\n  research_domains: existingPayload.research_domains || [],\n  methodologies: existingPayload.methodologies || [],\n  research_themes: existingPayload.research_themes || [],\n  h_index: existingPayload.h_index,\n  total_citations: existingPayload.total_citations,\n  publication_count: existingPayload.publication_count,\n  patent_count: existingPayload.patent_count,\n  career_stage: existingPayload.career_stage,\n  research_impact: existingPayload.research_impact,\n  data_completeness: existingPayload.data_completeness,\n  fabricated_at: existingPayload.fabricated_at,\n  \n  // Status update\n  status: \"classified\",\n  \n  // Standard A (ANZSRC) classification fields\n  classifications: classificationCodesA,\n  classification_confidences: classificationConfidencesA,\n  classification_taxonomy: \"ANZSRC_FoR_2020\",\n  \n  // Standard B (OECD FOS) classification fields\n  standard_b_codes: classificationCodesB,\n  standard_b_confidences: classificationConfidencesB,\n  standard_b_taxonomy: \"OECD_FOS_2007\",\n  \n  // Combined confidence metrics\n  final_confidence: inputData.final_confidence,\n  cf1_passed: inputData.cf1_assessment?.passed || false,\n  crosswalk_alignment_score: inputData.crosswalk_assessment?.alignment_score || null,\n  \n  // Validation state\n  classified_at: inputData.classified_at,\n  classified_by: \"object3_classifier_v3.5\",\n  validation_state: \"PENDING\"\n};\n\n// Build Qdrant request\nconst qdrantPayload = {\n  payload: mergedPayload,\n  points: [inputData.qdrant_point_id]\n};\n\nconsole.log(`‚úÖ Qdrant payload prepared:`);\nconsole.log(`   Standard A: ${classificationCodesA.length} codes`);\nconsole.log(`   Standard B: ${classificationCodesB.length} codes`);\n\nreturn [{\n  json: {\n    asset_id: inputData.asset_id,\n    name: inputData.name,\n    qdrant_point_id: inputData.qdrant_point_id,\n    classifications: inputData.classifications,\n    classification_count: inputData.classification_count,\n    standard_b_classifications: inputData.standard_b_classifications,\n    standard_b_count: inputData.standard_b_count,\n    final_confidence: inputData.final_confidence,\n    cf1_assessment: inputData.cf1_assessment,\n    crosswalk_assessment: inputData.crosswalk_assessment,\n    confidence_breakdown: inputData.confidence_breakdown,\n    reasoning: inputData.reasoning,\n    classified_at: inputData.classified_at,\n    qdrant_payload: qdrantPayload\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -640,
        896
      ],
      "id": "a8415e22-0c99-4aaa-9f30-a33bae793664",
      "name": "Prepare Qdrant Payload"
    },
    {
      "parameters": {
        "jsCode": "// Node: Prepare Fetch FATObjects\n// PURPOSE: Fetch specific researcher OR all fabricated if none specified\n\nconst inputData = $input.first().json;\n\n// Use provided asset_id, or fetch all if not specified\nconst specificAssetId = inputData.asset_id || null;\n\nlet cypherPayload;\n\nif (specificAssetId) {\n  // Fetch specific researcher\n  cypherPayload = {\n    statement: `\n      MATCH (fat:FATObject)\n      WHERE fat.asset_id = $asset_id\n        AND fat.status = 'fabricated'\n      RETURN \n          fat.asset_id AS asset_id,\n          fat.name AS name,\n          fat.orcid AS orcid,\n          fat.institution AS institution,\n          fat.dense_view AS dense_view,\n          fat.data_completeness AS data_completeness,\n          fat.status AS status,\n          fat.version AS version,\n          fat.fabricated_at AS fabricated_at\n    `,\n    parameters: {\n      asset_id: specificAssetId\n    }\n  };\n} else {\n  // Fetch ALL fabricated researchers\n  cypherPayload = {\n    statement: `\n      MATCH (fat:FATObject)\n      WHERE fat.status = 'fabricated'\n      RETURN \n          fat.asset_id AS asset_id,\n          fat.name AS name,\n          fat.orcid AS orcid,\n          fat.institution AS institution,\n          fat.dense_view AS dense_view,\n          fat.data_completeness AS data_completeness,\n          fat.status AS status,\n          fat.version AS version,\n          fat.fabricated_at AS fabricated_at\n      ORDER BY fat.fabricated_at DESC\n    `,\n    parameters: {}\n  };\n}\n\nreturn [{\n  json: {\n    requested_asset_id: specificAssetId,\n    fetch_mode: specificAssetId ? 'single' : 'all',\n    neo4j_payload: cypherPayload\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1024,
        0
      ],
      "id": "3c49229b-8d43-4f99-ba9c-da64e7ca176c",
      "name": "Prepare Fetch FATObjects"
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "https://3d3d355d-350c-4fd3-a844-17ca2599c7c0.europe-west3-0.gcp.cloud.qdrant.io/collections/objects_researchers_v1/points/payload",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "qdrantRestApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"payload\": {\n    \"asset_id\": \"fat:researcher:colin_barrow\",\n    \"object_type\": \"researcher\",\n    \"name\": \"Colin Barrow\",\n    \"institution\": \"Deakin University\",\n    \"orcid\": \"0000-0002-2153-7267\",\n    \"research_domains\": [\"Biotechnology\", \"Chemistry\", \"Food Science\", \"Nanotechnology\"],\n    \"methodologies\": [\"Lipase modification\", \"Bioprocessing techniques\", \"Natural product extraction\", \"Nanomaterial synthesis\", \"Biochemical analysis\"],\n    \"research_themes\": [\"Omega-3 oil enhancement\", \"Biotechnological applications of lipases\", \"Development of amyloid fibres\", \"Nanomaterial integration in food\", \"Biological chemistry of natural products\"],\n    \"h_index\": 79,\n    \"total_citations\": 25153,\n    \"publication_count\": 448,\n    \"patent_count\": 14,\n    \"career_stage\": \"established\",\n    \"research_impact\": \"Leading\",\n    \"data_completeness\": 100,\n    \"fabricated_at\": \"2025-12-01T12:00:00.000Z\",\n    \"status\": \"fabricated\"\n  },\n  \"points\": [\"66aa6d12-001b-4000-8000-000221ea81ec\"]\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        2032,
        1504
      ],
      "id": "baa995e2-661c-4d6e-8201-6f349e04a39d",
      "name": "Update Qdrant1",
      "credentials": {
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        }
      }
    },
    {
      "parameters": {
        "method": "PUT",
        "url": "https://3d3d355d-350c-4fd3-a844-17ca2599c7c0.europe-west3-0.gcp.cloud.qdrant.io/collections/objects_researchers_v1/points/payload",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "qdrantRestApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={\n  \"payload\": {\n    \"asset_id\": \"fat:researcher:colin_barrow\",\n    \"object_type\": \"researcher\",\n    \"name\": \"Colin Barrow\",\n    \"institution\": \"Deakin University\",\n    \"orcid\": \"0000-0002-2153-7267\",\n    \"research_domains\": [\"Biotechnology\", \"Chemistry\", \"Food Science\", \"Nanotechnology\"],\n    \"methodologies\": [\"Lipase modification\", \"Bioprocessing techniques\", \"Natural product extraction\", \"Nanomaterial synthesis\", \"Biochemical analysis\"],\n    \"research_themes\": [\"Omega-3 oil enhancement\", \"Biotechnological applications of lipases\", \"Development of amyloid fibres\", \"Nanomaterial integration in food\", \"Biological chemistry of natural products\"],\n    \"h_index\": 79,\n    \"total_citations\": 25153,\n    \"publication_count\": 448,\n    \"patent_count\": 14,\n    \"career_stage\": \"established\",\n    \"research_impact\": \"Leading\",\n    \"data_completeness\": 100,\n    \"fabricated_at\": \"2025-12-01T12:00:00.000Z\",\n    \"status\": \"classified\",\n    \"classifications\": [310601, 310602, 401807, 300602, 340303, 300102, 340401],\n    \"classification_confidences\": [0.9, 0.88, 0.88, 0.87, 0.86, 0.85, 0.84],\n    \"final_confidence\": 0.8686,\n    \"classified_at\": \"2025-12-05T15:25:38.778Z\",\n    \"classified_by\": \"object3_classifier_v1\",\n    \"cf1_passed\": true,\n    \"validation_state\": \"PENDING\"\n  },\n  \"points\": [\"66aa6d12-001b-4000-8000-000221ea81ec\"]\n}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1984,
        1264
      ],
      "id": "a0652152-4aa1-4f19-9195-fbe070f0ac1e",
      "name": "Update Qdrant2",
      "credentials": {
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://8b9cbf46.databases.neo4j.io/db/neo4j/query/v2",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.neo4j_status_payload }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        816,
        0
      ],
      "id": "bd5dac40-1f21-4ac5-8969-20f9ce0416a7",
      "name": "Execute Status Update to Classifying",
      "credentials": {
        "httpBasicAuth": {
          "id": "HximmqteOLptnTyu",
          "name": "Neo4j Gen 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Verify status was updated, then pass through original data\nconst neo4jResponse = $input.first().json;\nconst originalData = $('Prepare Status Update to Classifying').first().json;\n\n// Check update succeeded\nconst values = neo4jResponse.data?.values || [];\nif (values.length === 0) {\n  throw new Error('Failed to update status to classifying');\n}\n\nconst updatedStatus = values[0][1];\nif (updatedStatus !== 'classifying') {\n  throw new Error(`Expected status 'classifying', got '${updatedStatus}'`);\n}\n\n// Pass through original data with confirmed status\nreturn [{\n  json: {\n    ...originalData,\n    status: 'classifying',  // Confirmed updated\n    classification_started_at: new Date().toISOString()\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1024,
        0
      ],
      "id": "afbe56dd-55f7-4a69-8c95-ee149d6eac50",
      "name": "Parse Status Update Response"
    },
    {
      "parameters": {
        "jsCode": "// Add this node AFTER \"Parse Neo4j Response\"\nconst inputData = $input.first().json;\n\nreturn [{\n  json: {\n    ...inputData,\n    neo4j_status_payload: {\n      statement: `\n        MATCH (fat:FATObject {asset_id: $asset_id})\n        SET fat.status = 'classifying',\n            fat.classification_started_at = datetime()\n        RETURN fat.asset_id, fat.status\n      `,\n      parameters: {\n        asset_id: inputData.asset_id\n      }\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        560,
        0
      ],
      "id": "e4b1bc9a-bf20-4249-8c2a-29aea7983930",
      "name": "Prepare Status Update to Classifying"
    },
    {
      "parameters": {
        "jsCode": "// Prepare Crosswalk Assessment Query\n// Check [:MAPS_TO] alignment between assigned Standard A and Standard B codes\n\nconst inputData = $input.first().json;\n\nconst standardACodes = inputData.classifications.map(c => parseInt(c.code, 10));\nconst standardBCodes = inputData.standard_b_classifications.map(c => c.code);\n\n// If no Standard B classifications, skip crosswalk assessment\nif (standardBCodes.length === 0) {\n  console.log('‚ö†Ô∏è No Standard B codes - skipping crosswalk assessment');\n  return [{\n    json: {\n      ...inputData,\n      crosswalk_assessment: {\n        skipped: true,\n        reason: 'No Standard B classifications',\n        alignment_score: null,\n        modifier: 0.0\n      }\n    }\n  }];\n}\n\n// Query: For each assigned ANZSRC code, what FOS codes does it map to?\nconst cypherPayload = {\n  statement: `\n    UNWIND $anzsrc_codes AS anzsrc_code\n    MATCH (a:Standard:FoR {code: anzsrc_code})\n    OPTIONAL MATCH (a)-[m:MAPS_TO_V2]->(b:Standard:OECD_FOS)\n    RETURN \n      a.code AS anzsrc_code,\n      a.name AS anzsrc_name,\n      collect(CASE WHEN b IS NOT NULL THEN {\n        fos_code: b.code,\n        fos_name: b.name,\n        confidence: m.confidence,\n        alignment_score: m.alignment_score,\n        mapping_type: m.mapping_type\n      } ELSE NULL END) AS mapped_fos_codes\n  `,\n  parameters: {\n    anzsrc_codes: standardACodes\n  }\n};\n\nreturn [{\n  json: {\n    ...inputData,\n    standard_a_codes: standardACodes,\n    standard_b_codes: standardBCodes,\n    neo4j_payload: cypherPayload\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -688,
        624
      ],
      "id": "c182f6a4-c94e-47a5-ac43-127f312bcbcf",
      "name": "Prepare Crosswalk Assessment Query"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://8b9cbf46.databases.neo4j.io/db/neo4j/query/v2",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.neo4j_payload }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -464,
        624
      ],
      "id": "7a99cd02-89b0-48fa-9197-89790b505d14",
      "name": "Execute Crosswalk Assessment",
      "credentials": {
        "httpBasicAuth": {
          "id": "HximmqteOLptnTyu",
          "name": "Neo4j Gen 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Calculate Crosswalk Alignment Score (FIXED)\n// v3.6.2 FIX: Code-level alignment instead of mapping-level\n// \n// OLD (flawed): alignedMappings / totalMappings\n//   - If code maps to 5 FOS and only 1 matches, that's 20% per code\n//   - Unfairly penalizes codes with many crosswalk relationships\n//\n// NEW (fixed): codesWithMatch / codesChecked  \n//   - If code has ANY matching FOS, it counts as aligned\n//   - Fair assessment: \"Does this ANZSRC code align with assigned FOS?\"\n\nconst neo4jResponse = $input.first().json;\nconst prevData = $('Prepare Crosswalk Assessment Query').first().json;\n\n// Handle skipped assessment\nif (prevData.crosswalk_assessment?.skipped) {\n  return [{ json: prevData }];\n}\n\n// Parse Neo4j response\nconst responseData = Array.isArray(neo4jResponse) ? neo4jResponse[0] : neo4jResponse;\n\nif (responseData.errors?.length > 0) {\n  console.error('Neo4j error:', responseData.errors[0].message);\n  return [{\n    json: {\n      ...prevData,\n      crosswalk_assessment: {\n        error: responseData.errors[0].message,\n        alignment_score: null,\n        modifier: 0.0\n      }\n    }\n  }];\n}\n\nconst values = responseData.data?.values || [];\nconst assignedFosCodes = new Set(prevData.standard_b_codes);\n\n// ============================================================\n// v3.6.2 FIX: Track CODE-LEVEL alignment (not mapping-level)\n// ============================================================\nlet codesWithMatch = 0;\nlet codesChecked = 0;\nlet codesWithNoCrosswalk = 0;\n\n// Still track mapping-level for detailed reporting\nlet totalMappings = 0;\nlet alignedMappings = 0;\n\nconst alignmentDetails = [];\n\nfor (const row of values) {\n  const anzsrcCode = row[0];\n  const anzsrcName = row[1];\n  const mappedFosCodes = (row[2] || []).filter(m => m !== null);\n  \n  if (mappedFosCodes.length === 0) {\n    // No crosswalk exists for this code\n    codesWithNoCrosswalk += 1;\n    alignmentDetails.push({\n      anzsrc_code: anzsrcCode,\n      anzsrc_name: anzsrcName,\n      status: 'no_crosswalk',\n      mapped_fos: [],\n      aligned: false\n    });\n    continue;\n  }\n  \n  // This code has crosswalks - count it for alignment calculation\n  codesChecked += 1;\n  \n  // Check if ANY mapped FOS code matches an assigned FOS code\n  const matchingMappings = mappedFosCodes.filter(m => assignedFosCodes.has(m.fos_code));\n  const hasMatch = matchingMappings.length > 0;\n  \n  if (hasMatch) {\n    codesWithMatch += 1;\n  }\n  \n  // Track individual mappings for detailed reporting\n  totalMappings += mappedFosCodes.length;\n  alignedMappings += matchingMappings.length;\n  \n  alignmentDetails.push({\n    anzsrc_code: anzsrcCode,\n    anzsrc_name: anzsrcName,\n    status: hasMatch ? 'aligned' : 'misaligned',\n    mapped_fos: mappedFosCodes.map(m => ({\n      code: m.fos_code,\n      name: m.fos_name,\n      confidence: m.confidence,\n      matches_assigned: assignedFosCodes.has(m.fos_code)\n    })),\n    aligned: hasMatch,\n    matching_count: matchingMappings.length,\n    total_mappings: mappedFosCodes.length\n  });\n}\n\n// ============================================================\n// v3.6.2 FIX: CODE-LEVEL alignment score\n// Question: \"What % of ANZSRC codes have at least one matching FOS?\"\n// ============================================================\nlet alignmentScore = codesChecked > 0 \n  ? Math.round((codesWithMatch / codesChecked) * 100) / 100 \n  : null;\n\n// Also calculate mapping-level for reference (but don't use for modifier)\nlet mappingLevelScore = totalMappings > 0\n  ? Math.round((alignedMappings / totalMappings) * 100) / 100\n  : null;\n\n// ============================================================\n// Three-tier modifier system (unchanged thresholds)\n// ============================================================\n// >= 0.50: Strong alignment   ‚Üí +5% boost\n// 0.30 - 0.49: Acceptable     ‚Üí 0% neutral\n// < 0.30: Poor alignment      ‚Üí -15% penalty\n// ============================================================\n\nlet modifier = 0.0;\nlet alignmentStatus = 'unknown';\n\nif (alignmentScore === null) {\n  // No crosswalks exist (Gen 2 fallback)\n  modifier = 0.0;\n  alignmentStatus = 'no_crosswalks';\n} else if (alignmentScore >= 0.50) {\n  // Strong alignment: boost confidence\n  modifier = 0.05;\n  alignmentStatus = 'aligned';\n} else if (alignmentScore >= 0.30) {\n  // Acceptable alignment: neutral (no penalty, no boost)\n  modifier = 0.0;\n  alignmentStatus = 'acceptable';\n} else {\n  // Poor alignment: penalize confidence\n  modifier = -0.15;\n  alignmentStatus = 'misaligned';\n}\n\n// Detailed logging\nconsole.log(`‚úÖ Crosswalk Assessment (v3.6.2 - code-level):`);\nconsole.log(`   ANZSRC codes checked: ${codesChecked}`);\nconsole.log(`   Codes with FOS match: ${codesWithMatch}`);\nconsole.log(`   Codes with no crosswalk: ${codesWithNoCrosswalk}`);\nconsole.log(`   CODE-LEVEL alignment: ${alignmentScore !== null ? (alignmentScore * 100).toFixed(0) + '%' : 'N/A'}`);\nconsole.log(`   (mapping-level was: ${mappingLevelScore !== null ? (mappingLevelScore * 100).toFixed(0) + '%' : 'N/A'})`);\nconsole.log(`   Status: ${alignmentStatus}`);\nconsole.log(`   Modifier: ${modifier >= 0 ? '+' : ''}${(modifier * 100).toFixed(0)}%`);\n\n// Log which codes aligned and which didn't\nconst alignedCodes = alignmentDetails.filter(d => d.aligned);\nconst misalignedCodes = alignmentDetails.filter(d => d.status === 'misaligned');\nif (alignedCodes.length > 0) {\n  console.log(`   Aligned: ${alignedCodes.map(d => d.anzsrc_code).join(', ')}`);\n}\nif (misalignedCodes.length > 0) {\n  console.log(`   Misaligned: ${misalignedCodes.map(d => d.anzsrc_code).join(', ')}`);\n}\n\nreturn [{\n  json: {\n    // Core data\n    asset_id: prevData.asset_id,\n    name: prevData.name,\n    qdrant_point_id: prevData.qdrant_point_id,\n    \n    // Classifications\n    classifications: prevData.classifications,\n    classification_count: prevData.classification_count,\n    standard_b_classifications: prevData.standard_b_classifications,\n    standard_b_count: prevData.standard_b_count,\n    reasoning: prevData.reasoning,\n    model: prevData.model,\n    \n    // Crosswalk assessment (v3.6.2 - code-level)\n    crosswalk_assessment: {\n      skipped: false,\n      \n      // PRIMARY: Code-level alignment (used for modifier)\n      alignment_score: alignmentScore,\n      alignment_status: alignmentStatus,\n      modifier: modifier,\n      \n      // Code-level stats\n      codes_checked: codesChecked,\n      codes_with_match: codesWithMatch,\n      codes_with_no_crosswalk: codesWithNoCrosswalk,\n      \n      // Mapping-level stats (for reference only)\n      total_mappings_checked: totalMappings,\n      aligned_mappings: alignedMappings,\n      mapping_level_score: mappingLevelScore,\n      \n      // Detailed breakdown\n      details: alignmentDetails\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -224,
        624
      ],
      "id": "aee59240-cfe1-4fe9-90fa-4848f5700bdb",
      "name": "Calculate Crosswalk Alignment"
    },
    {
      "parameters": {
        "jsCode": "// Prepare PostgreSQL Classification Log\n// Creates audit record for classification job\n\nconst inputData = $('Prepare Qdrant Payload').first().json;\n\n// Generate classification job ID\nconst jobId = `clf_${inputData.asset_id.replace(/[^a-zA-Z0-9]/g, '_')}_${Date.now()}`;\n\nconst postgresPayload = {\n  job_id: jobId,\n  asset_id: inputData.asset_id,\n  asset_type: 'researcher',\n  \n  // Standard A summary\n  standard_a_taxonomy: 'ANZSRC_FoR_2020',\n  standard_a_codes: inputData.classifications.map(c => parseInt(c.code, 10)),\n  standard_a_count: inputData.classification_count,\n  \n  // Standard B summary\n  standard_b_taxonomy: 'OECD_FOS_2007',\n  standard_b_codes: (inputData.standard_b_classifications || []).map(c => c.code),\n  standard_b_count: inputData.standard_b_count || 0,\n  \n  // Confidence metrics\n  final_confidence: inputData.final_confidence,\n  cf1_passed: inputData.cf1_assessment?.passed || false,\n  cf1_penalty: inputData.cf1_assessment?.penalty || 0,\n  crosswalk_alignment_score: inputData.crosswalk_assessment?.alignment_score || null,\n  crosswalk_modifier: inputData.crosswalk_assessment?.modifier || 0,\n  \n  // Metadata\n  classified_at: inputData.classified_at,\n  classified_by: 'object3_classifier_v3.5',\n  model: 'openai/gpt-4o',\n  workflow_version: 'OBJECT-3_v3.6',\n  \n  // Routing preview (for OBJECT-4)\n  routing_recommendation: inputData.final_confidence >= 0.85 \n    ? 'AUTO_APPROVE' \n    : inputData.final_confidence >= 0.60 \n      ? 'HUMAN_REVIEW' \n      : 'REJECT'\n};\n\nreturn [{\n  json: {\n    ...inputData,\n    postgres_payload: postgresPayload\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -176,
        896
      ],
      "id": "ecb3db4e-5c5a-4786-b832-7f38c945c0e7",
      "name": "Prepare PostgreSQL Classification Log"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://esgwrqcyhtzcsbepvqhc.supabase.co/rest/v1/classification_logs",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "prefer",
              "value": "resolution=merge-duplicates,return=representation"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.postgres_payload }}",
        "options": {
          "timeout": 30000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        80,
        896
      ],
      "id": "6e059952-b2fb-423c-9f08-ec903fbfe4a4",
      "name": "Store Crosswalk Metadata",
      "credentials": {
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        },
        "supabaseApi": {
          "id": "vTKATqGswB3PHE6S",
          "name": "Supabase account"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://8b9cbf46.databases.neo4j.io/db/neo4j/query/v2",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.neo4j_cre_payload }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1760,
        1280
      ],
      "id": "12d5c60c-ea7b-4b1e-88b9-ba942008c4fd",
      "name": "Execute CRE Constraint Query",
      "credentials": {
        "httpBasicAuth": {
          "id": "HximmqteOLptnTyu",
          "name": "Neo4j Gen 2"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// CF1 Hierarchical Consistency Check\n// Validates classification hierarchy and checks for constraint violations\n// UPDATED: Handle empty classifications gracefully\n// ============================================================\n\nconst inputData = $input.first().json;\n\n// === Handle empty classifications (candidate mismatch) ===\nif (!inputData.classifications || inputData.classifications.length === 0) {\n  console.log(`‚ö†Ô∏è No ANZSRC classifications for ${inputData.name} - routing to HITL`);\n  \n  // Check if we have Standard B classifications (OECD FOS)\n  const hasStandardB = inputData.standard_b_classifications && \n                       inputData.standard_b_classifications.length > 0;\n  \n  return [{\n    json: {\n      // Core data (pass through)\n      asset_id: inputData.asset_id,\n      name: inputData.name,\n      qdrant_point_id: inputData.qdrant_point_id,\n      reasoning: inputData.reasoning,\n      model: inputData.model,\n      \n      // Crosswalk assessment (pass through)\n      crosswalk_assessment: inputData.crosswalk_assessment,\n      \n      // CRE assessment (pass through)\n      cre_assessment: inputData.cre_assessment,\n      \n      // Standard B classifications (pass through)\n      standard_b_classifications: inputData.standard_b_classifications,\n      standard_b_count: inputData.standard_b_count,\n      \n      // Empty Standard A - this is the problem\n      classifications: [],\n      classification_count: 0,\n      \n      // CF1 Assessment - mark as failed due to no classifications\n      cf1_assessment: {\n        passed: false,\n        violations: [],\n        flags: [{\n          rule: 'no_anzsrc_classifications',\n          message: 'LLM could not assign any ANZSRC codes from candidates - likely candidate mismatch',\n          has_standard_b: hasStandardB,\n          standard_b_count: inputData.standard_b_count || 0\n        }],\n        penalty: 0.5,\n        divisions_found: [],\n        groups_found: []\n      },\n      \n      // Route to HITL\n      requires_hitl: true,\n      hitl_reason: 'No ANZSRC classifications - vector search returned irrelevant candidates',\n      classification_failed: false,\n      candidate_mismatch: true\n    }\n  }];\n}\n\n// === Normal processing continues below ===\n\n// Extract hierarchy info from each code\nconst classificationDetails = inputData.classifications.map(c => {\n  const code = String(c.code);\n  return {\n    ...c,\n    division_code: code.substring(0, 2),\n    group_code: code.substring(0, 4),\n    field_code: code\n  };\n});\n\n// Get unique divisions and groups\nconst divisionsFound = [...new Set(classificationDetails.map(c => c.division_code))];\nconst groupsFound = [...new Set(classificationDetails.map(c => c.group_code))];\n\n// === CF1 RULE 1: Check parent-child conflicts ===\nconst violations = [];\nconst codes = classificationDetails.map(c => c.code);\n\nfor (const c of classificationDetails) {\n  for (const other of codes) {\n    if (other !== c.code) {\n      if (c.code.startsWith(other) && c.code.length > other.length) {\n        violations.push({\n          rule: 'parent_child_conflict',\n          parent: other,\n          child: c.code,\n          action: `Remove parent code ${other}, keep specific code ${c.code}`\n        });\n      }\n    }\n  }\n}\n\n// === CF1 RULE 2: Check code specificity (warn on broad codes) ===\nconst flags = [];\nfor (const c of classificationDetails) {\n  if (c.code.length === 2) {\n    flags.push({\n      rule: 'broad_code_warning',\n      code: c.code,\n      message: '2-digit code is very broad, consider more specific classification'\n    });\n  } else if (c.code.length === 4) {\n    flags.push({\n      rule: 'group_code_warning',\n      code: c.code,\n      message: '4-digit group code used instead of 6-digit field code'\n    });\n  }\n}\n\n// === CF1 RULE 3: Check sibling overlap ===\nconst parentGroups = {};\nfor (const c of classificationDetails) {\n  if (c.code.length === 6) {\n    const parent = c.group_code;\n    if (!parentGroups[parent]) {\n      parentGroups[parent] = [];\n    }\n    parentGroups[parent].push(c.code);\n  }\n}\n\nfor (const [parent, children] of Object.entries(parentGroups)) {\n  if (children.length > 2) {\n    flags.push({\n      rule: 'sibling_overlap',\n      parent: parent,\n      siblings: children,\n      message: `Multiple codes (${children.length}) under group ${parent} may indicate over-classification`\n    });\n  }\n}\n\n// === Calculate penalty ===\nlet penalty = 0.0;\npenalty += violations.length * 0.10;\npenalty += flags.filter(f => f.rule === 'broad_code_warning').length * 0.05;\n\nconst passed = violations.length === 0;\n\n// === Build adjusted classifications ===\nconst codesToRemove = new Set(violations.map(v => v.parent));\n\nconst adjustedClassifications = classificationDetails\n  .filter(c => !codesToRemove.has(c.code))\n  .map(c => ({\n    code: c.code,\n    name: c.name,\n    confidence: c.confidence,\n    justification: c.justification,\n    evidence: c.evidence,\n    division_code: c.division_code,\n    group_code: c.group_code,\n    cf1_validated: passed\n  }));\n\n// === Enforce min/max code counts ===\nconst MIN_CODES = 3;\nconst MAX_CODES = 10;\n\nif (adjustedClassifications.length < MIN_CODES) {\n  flags.push({\n    rule: 'under_classification',\n    count: adjustedClassifications.length,\n    message: `Only ${adjustedClassifications.length} codes assigned, minimum is ${MIN_CODES}`\n  });\n}\n\nif (adjustedClassifications.length > MAX_CODES) {\n  adjustedClassifications.sort((a, b) => b.confidence - a.confidence);\n  adjustedClassifications.splice(MAX_CODES);\n  flags.push({\n    rule: 'over_classification_truncated',\n    message: `Truncated to ${MAX_CODES} highest-confidence codes`\n  });\n}\n\nconsole.log(`‚úÖ CF1 Assessment: ${passed ? 'PASSED' : 'FAILED'}`);\nconsole.log(`   Violations: ${violations.length}, Flags: ${flags.length}, Penalty: ${penalty}`);\n\nreturn [{\n  json: {\n    // Core data (pass through)\n    asset_id: inputData.asset_id,\n    name: inputData.name,\n    qdrant_point_id: inputData.qdrant_point_id,\n    reasoning: inputData.reasoning,\n    model: inputData.model,\n    \n    // Crosswalk assessment (pass through)\n    crosswalk_assessment: inputData.crosswalk_assessment,\n    \n    // CRE assessment (pass through)\n    cre_assessment: inputData.cre_assessment,\n    \n    // Standard B classifications (pass through)\n    standard_b_classifications: inputData.standard_b_classifications,\n    standard_b_count: inputData.standard_b_count,\n    \n    // CF1 Assessment results\n    cf1_assessment: {\n      passed: passed,\n      violations: violations,\n      flags: flags,\n      penalty: penalty,\n      divisions_found: divisionsFound,\n      groups_found: groupsFound\n    },\n    \n    // Adjusted Standard A classifications\n    classifications: adjustedClassifications,\n    classification_count: adjustedClassifications.length,\n    \n    // Normal path - no HITL override\n    requires_hitl: false,\n    candidate_mismatch: false\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        752,
        624
      ],
      "id": "1212d874-8f04-411f-b571-3d32faf64800",
      "name": "ANZSRC Hierarchy Check"
    },
    {
      "parameters": {
        "workflowId": {
          "__rl": true,
          "value": "7wgDbsjDcjLdQNSJ",
          "mode": "id",
          "cachedResultUrl": "/workflow/7wgDbsjDcjLdQNSJ"
        },
        "workflowInputs": {
          "mappingMode": "defineBelow",
          "value": {},
          "matchingColumns": [],
          "schema": [],
          "attemptToConvertTypes": false,
          "convertFieldsToString": true
        },
        "mode": "each",
        "options": {
          "waitForSubWorkflow": true
        }
      },
      "type": "n8n-nodes-base.executeWorkflow",
      "typeVersion": 1.2,
      "position": [
        320,
        624
      ],
      "name": "SYSTEM-2_CRE_Assessment",
      "id": "5d82582e-c98d-4d39-9c05-43059b4c707e"
    },
    {
      "parameters": {
        "jsCode": "// Merge CRE Output\nconst creOutput = $input.first().json;  // From SYSTEM-2\nconst prevData = $('Calculate Crosswalk Alignment').first().json;  // Get data from before CRE\n\nconsole.log(`‚úÖ CRE Assessment Received:`);\nconsole.log(`   Blocking: ${creOutput.blocking_failures?.join(', ') || 'None'}`);\nconsole.log(`   HITL Required: ${creOutput.requires_hitl}`);\n\nreturn [{\n  json: {\n    // Pass through from earlier node\n    asset_id: prevData.asset_id,\n    name: prevData.name,\n    qdrant_point_id: prevData.qdrant_point_id,\n    classifications: prevData.classifications,\n    classification_count: prevData.classification_count,\n    standard_b_classifications: prevData.standard_b_classifications,\n    standard_b_count: prevData.standard_b_count,\n    reasoning: prevData.reasoning,\n    model: prevData.model,\n    crosswalk_assessment: prevData.crosswalk_assessment,\n    \n    // CRE Assessment (from SYSTEM-2)\n    cre_assessment: {\n      constraint_results: creOutput.constraint_results || {},\n      blocking_failures: creOutput.blocking_failures || [],\n      penalising_failures: creOutput.penalising_failures || [],\n      requires_hitl: creOutput.requires_hitl || false,\n      cre_penalty: Math.abs(creOutput.final_confidence_modifier || 0)\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        544,
        624
      ],
      "id": "0a937ddf-e81e-4466-adc3-914dadc59dbe",
      "name": "Merge CRE Output"
    },
    {
      "parameters": {
        "jsCode": "// Prepare CRE Input\n// Gen 4: Build input contract for SYSTEM-2_CRE_Assessment sub-workflow\n\nconst inputData = $input.first().json;\nconst signals = $('Merge Embedding').first().json;\n\n// Infer TRL from researcher signals\nfunction inferTRLLevel(s) {\n  const hasPatents = (s.patent_count || 0) > 0;\n  const careerStage = (s.career_stage || '').toLowerCase();\n  const impact = (s.research_impact || '').toLowerCase();\n  \n  if (hasPatents && (careerStage === 'established' || careerStage === 'senior')) return 7;\n  if (impact === 'leading' || impact === 'high') return 6;\n  if (careerStage === 'mid-career' || (s.h_index || 0) > 20) return 5;\n  if (careerStage === 'early-career' || careerStage === 'emerging') return 3;\n  return 4;\n}\n\n// Determine inference type\n// Only use 'patent' or 'publication' if NO explicit expertise declared\nlet inference_type = 'explicit';\n\nconst hasExplicitExpertise = \n  (signals.research_domains?.length > 0) ||\n  (signals.methodologies?.length > 0) ||\n  (signals.research_themes?.length > 0);\n\nif (!hasExplicitExpertise) {\n  // No explicit declaration - infer from other signals\n  if ((signals.patent_count || 0) > 0) {\n    inference_type = 'patent';\n  } else if ((signals.publication_count || 0) > 0) {\n    inference_type = 'publication';\n  } else {\n    inference_type = 'keyword';\n  }\n}\n\n// Average classification confidence\nconst avgConfidence = inputData.classifications.length > 0\n  ? inputData.classifications.reduce((a, c) => a + c.confidence, 0) / inputData.classifications.length\n  : 0;\n\n// Output CRE contract at ROOT level\nreturn [{\n  json: {\n    asset_id: inputData.asset_id,\n    classification_confidence: avgConfidence,\n    entity_data: {\n      trl_level: inferTRLLevel(signals),\n      certifications: [],\n      inference_type: inference_type\n    },\n    requirements: {\n      required_trl: 5,\n      required_certifications: []\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        64,
        624
      ],
      "id": "4fcb3416-9ad5-43a4-94b8-95d0f3a6af05",
      "name": "Prepare CRE Input"
    },
    {
      "parameters": {
        "model": "openai/gpt-oss-120b",
        "options": {}
      },
      "type": "@n8n/n8n-nodes-langchain.lmChatOpenRouter",
      "typeVersion": 1,
      "position": [
        1616,
        512
      ],
      "id": "fe7fbc79-3674-4e94-bc6c-1f3466153f94",
      "name": "OpenRouter Chat Model",
      "credentials": {
        "openRouterApi": {
          "id": "1srwGILgkvMmHRRn",
          "name": "OpenRouter account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Prepare FOS Vector Search (Standard B)\n// Uses direct reference to get embedding from source node\n\nconst inputData = $input.first().json;\n\n// Get embedding directly from \"Merge Embedding\" node\nconst mergeEmbeddingData = $('Merge Embedding').first().json;\nconst embeddingVector = mergeEmbeddingData.embedding_vector;\n\n// Validate embedding\nif (!embeddingVector || embeddingVector.length !== 3072) {\n  throw new Error(`Invalid embedding vector from Merge Embedding. Expected 3072 dimensions, got ${embeddingVector?.length || 0}`);\n}\n\n// ============================================================\n// OECD FOS collection already contains ONLY FOS codes\n// No need to filter by taxonomy - the collection IS the filter\n// ============================================================\nconst qdrantFosRequest = {\n  query: embeddingVector,\n  limit: 10,\n  with_payload: true,\n  with_vector: false\n  // No filter needed - collection is dedicated to FOS\n};\n\nreturn [{\n  json: {\n    // Pass through all data from previous node\n    asset_id: inputData.asset_id,\n    name: inputData.name,\n    orcid: inputData.orcid,\n    institution: inputData.institution,\n    qdrant_point_id: inputData.qdrant_point_id,\n    dense_view_text: inputData.dense_view_text,\n    research_domains: inputData.research_domains,\n    methodologies: inputData.methodologies,\n    research_themes: inputData.research_themes,\n    h_index: inputData.h_index,\n    career_stage: inputData.career_stage,\n    \n    // ANZSRC candidates (Standard A) - from reranking\n    field_candidates: inputData.field_candidates,\n    field_candidate_count: inputData.field_candidate_count,\n    reranking: inputData.reranking,\n    group_candidates: inputData.group_candidates,\n    retrieval_sources: inputData.retrieval_sources,\n    \n    // Store embedding for reference\n    embedding_vector: embeddingVector,\n    \n    // Qdrant request for FOS search (no filter)\n    qdrant_fos_request: qdrantFosRequest\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        624,
        288
      ],
      "id": "da5e6e9f-5d07-406a-bea8-b00075c37434",
      "name": "Prepare FOS Vector Search"
    },
    {
      "parameters": {
        "jsCode": "// Parse FOS Vector Search Results\n// Extracts OECD FOS candidates for dual-standard classification\n\nconst qdrantResponse = $input.first().json;\nconst originalData = $('Prepare FOS Vector Search').first().json;\n\n// Handle response structure (may be wrapped in array)\nconst responseData = Array.isArray(qdrantResponse) ? qdrantResponse[0] : qdrantResponse;\n\n// ============================================================\n// FAIL-SAFE: Handle errors or empty results\n// ============================================================\nif (responseData.status === 'error' || responseData.error) {\n  const errorMessage = responseData.status?.error || responseData.error || 'Unknown error';\n  console.log(`‚ö†Ô∏è FOS Vector Search error: ${errorMessage}`);\n  \n  return [{\n    json: {\n      ...originalData,\n      fos_candidates: [],\n      fos_candidate_count: 0,\n      fos_search_empty: true,\n      fos_search_error: errorMessage\n    }\n  }];\n}\n\nconst points = responseData.result?.points || [];\n\nif (points.length === 0) {\n  console.log('‚ö†Ô∏è FOS Vector Search: No candidates found - proceeding with ANZSRC only');\n  \n  return [{\n    json: {\n      ...originalData,\n      fos_candidates: [],\n      fos_candidate_count: 0,\n      fos_search_empty: true\n    }\n  }];\n}\n\n// Extract FOS candidates with scores and context\n// Filter to field-level only (exclude group-level like \"2\", \"3\")\nconst fosCandidates = points\n  .filter(point => point.payload.level === 'field')  // Only fields, not groups\n  .map(point => ({\n    code: point.payload.code,\n    name: point.payload.name,\n    score: point.score,\n    group_code: point.payload.group_code,\n    embedding_text: point.payload.embedding_text || null\n  }));\n\n// Log summary\nconsole.log(`‚úÖ FOS Vector Search: Found ${fosCandidates.length} field-level candidates`);\nconsole.log(`   Top 3: ${fosCandidates.slice(0, 3).map(c => `${c.code} ${c.name} (${c.score.toFixed(3)})`).join(', ')}`);\n\nreturn [{\n  json: {\n    // Pass through ALL researcher data\n    asset_id: originalData.asset_id,\n    name: originalData.name,\n    orcid: originalData.orcid,\n    institution: originalData.institution,\n    qdrant_point_id: originalData.qdrant_point_id,\n    dense_view_text: originalData.dense_view_text,\n    research_domains: originalData.research_domains,\n    methodologies: originalData.methodologies,\n    research_themes: originalData.research_themes,\n    h_index: originalData.h_index,\n    career_stage: originalData.career_stage,\n    \n    // ANZSRC candidates (Standard A) - from reranking\n    field_candidates: originalData.field_candidates,\n    field_candidate_count: originalData.field_candidate_count,\n    reranking: originalData.reranking,\n    group_candidates: originalData.group_candidates,\n    retrieval_sources: originalData.retrieval_sources,\n    \n    // NEW: FOS candidates (Standard B)\n    fos_candidates: fosCandidates,\n    fos_candidate_count: fosCandidates.length,\n    fos_search_empty: false\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1152,
        288
      ],
      "id": "3bc9f5b1-fd2e-4fc6-9e34-3c9e14dc0922",
      "name": "Parse FOS Candidates"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://3d3d355d-350c-4fd3-a844-17ca2599c7c0.europe-west3-0.gcp.cloud.qdrant.io/collections/standards_oecd_fos_2007/points/query",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "qdrantRestApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.qdrant_fos_request) }}",
        "options": {
          "response": {
            "response": {
              "responseFormat": "json"
            }
          }
        }
      },
      "id": "2342ffa8-e6bd-4bf9-bfc3-e6612f66f247",
      "name": "Vector Search FOS (Qdrant)",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        912,
        288
      ],
      "credentials": {
        "openRouterApi": {
          "id": "1srwGILgkvMmHRRn",
          "name": "OpenRouter account"
        },
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// Prepare Dual-Standard LLM Prompt\n// Version: v3.7.0\n// Aligned with: researcher_instance_spec_v2.2, OBJECT-3_Definition_Card_v3.7\n// ============================================================\n\nconst inputData = $input.first().json;\n\n// Get ANZSRC field candidates (Standard A) - Top 25 from reranking\nconst anzsrcCandidates = inputData.field_candidates || [];\n\n// Get FOS candidates (Standard B)\nconst fosCandidates = inputData.fos_candidates || [];\n\n// ============================================================\n// EXTRACT RAW EVIDENCE (v3.7 requirement)\n// ============================================================\nconst rawEvidence = inputData.raw_evidence || {};\nconst enrichedContext = inputData.enriched_context || {};\n\nconst publications = rawEvidence.publications || [];\nconst grants = rawEvidence.grants || [];\nconst biography = rawEvidence.biography || '';\nconst researchInterests = rawEvidence.research_interests || [];\n\n// ============================================================\n// FORMAT PUBLICATIONS FOR PROMPT (Top 15)\n// ============================================================\nconst pubList = publications.slice(0, 15).map((p, i) => {\n  const title = p.title || 'Untitled';\n  const year = p.year ? ` (${p.year})` : '';\n  const abstract = p.abstract ? `\\n     Abstract: ${p.abstract.slice(0, 200)}...` : '';\n  const keywords = (p.keywords || []).slice(0, 5).join(', ');\n  return `  ${i+1}. ${title}${year}${abstract}${keywords ? `\\n     Keywords: ${keywords}` : ''}`;\n}).join('\\n');\n\n// ============================================================\n// FORMAT GRANTS FOR PROMPT\n// ============================================================\nconst grantList = grants.slice(0, 10).map((g, i) => {\n  const title = g.title || 'Untitled Grant';\n  const funder = g.funder ? ` (${g.funder})` : '';\n  const amount = g.amount ? ` - $${Number(g.amount).toLocaleString()}` : '';\n  const dates = g.dates ? ` [${g.dates}]` : '';\n  return `  ${i+1}. ${title}${funder}${amount}${dates}`;\n}).join('\\n');\n\n// ============================================================\n// BUILD ANZSRC CANDIDATE LIST (Standard A)\n// ============================================================\nconst anzsrcList = anzsrcCandidates.map(f => {\n  return `  ${f.code} - ${f.name}`;\n}).join('\\n');\n\n// ============================================================\n// BUILD FOS CANDIDATE LIST (Standard B)\n// ============================================================\nconst fosList = fosCandidates.map(f => {\n  return `  ${f.code} - ${f.name}`;\n}).join('\\n');\n\n// ============================================================\n// DETERMINE CODE COUNT BASED ON CAREER STAGE\n// Per researcher_instance_spec_v2.2 Section 4.3\n// ============================================================\nconst careerStage = inputData.career_stage || enrichedContext.career_stage || 'mid-career';\n\nlet anzsrcCodeGuidance = '5-7';\nlet fosCodeGuidance = '2-4';\nlet careerStageDescription = 'mid-career researcher with multi-domain expertise';\n\nif (careerStage === 'early-career' || careerStage.includes('early')) {\n  anzsrcCodeGuidance = '3-5';\n  fosCodeGuidance = '2-3';\n  careerStageDescription = 'early-career researcher with focused expertise';\n} else if (careerStage === 'senior' || careerStage.includes('senior') || careerStage === 'emeritus') {\n  anzsrcCodeGuidance = '7-10';\n  fosCodeGuidance = '3-5';\n  careerStageDescription = 'senior/established researcher with highly interdisciplinary portfolio';\n}\n\n// ============================================================\n// BUILD CLASSIFICATION PROMPT (v3.7 / instance_spec v2.2)\n// ============================================================\nconst userPrompt = `You are a research classification specialist. Your task is to classify a researcher's profile against the Australian and New Zealand Standard Research Classification (ANZSRC) Field of Research (FoR) codes.\n\n============================================================\nRESEARCHER PROFILE\n============================================================\n\nName: ${inputData.name || 'Unknown'}\nInstitution: ${inputData.institution || 'Unknown'}\nORCID: ${inputData.orcid || 'Not available'}\n\n------------------------------------------------------------\nRAW EVIDENCE (from source data - use this for justifications)\n------------------------------------------------------------\n\nBIOGRAPHY:\n${biography || 'Not available'}\n\nRESEARCH INTERESTS:\n${researchInterests.length > 0 ? researchInterests.join(', ') : 'Not specified'}\n\nPUBLICATIONS (${publications.length} total, showing top ${Math.min(publications.length, 15)}):\n${pubList || '  No publications available'}\n\nGRANTS (${grants.length} total):\n${grantList || '  No grants available'}\n\n------------------------------------------------------------\nENRICHED CONTEXT (from LLM analysis)\n------------------------------------------------------------\n\nResearch Domains: ${(enrichedContext.research_domains || inputData.research_domains || []).join(', ') || 'Not extracted'}\n\nCore Methodologies: ${(enrichedContext.methodologies || inputData.methodologies || []).join(', ') || 'Not extracted'}\n\nResearch Themes: ${(enrichedContext.themes || inputData.research_themes || []).join(', ') || 'Not extracted'}\n\nKeywords: ${(enrichedContext.keywords || []).join(', ') || 'Not extracted'}\n\n------------------------------------------------------------\nMETRICS\n------------------------------------------------------------\n\nH-index: ${inputData.h_index || 0}\nCareer Stage: ${careerStage} (${careerStageDescription})\n\n============================================================\nDUAL-STANDARD CLASSIFICATION TASK\n============================================================\n\nYou must classify this researcher against TWO taxonomies independently.\n\n------------------------------------------------------------\nSTANDARD A: ANZSRC Field of Research 2020 (Primary Classification)\n------------------------------------------------------------\n\nAssign ${anzsrcCodeGuidance} codes from the candidates below.\nThese are specific 6-digit codes representing detailed research fields.\n\nCANDIDATE CODES (from hierarchical retrieval):\n${anzsrcList || '  No candidates available'}\n\n------------------------------------------------------------\nSTANDARD B: OECD Fields of Science 2007 (Domain Context)\n------------------------------------------------------------\n\nAssign ${fosCodeGuidance} codes from the candidates below.\nThese are broader international domain classifications.\n\nCANDIDATE CODES:\n${fosList || '  No candidates available'}\n\n------------------------------------------------------------\nCLASSIFICATION RULES\n------------------------------------------------------------\n\n1. ADAPTIVE CODE COUNT based on career stage:\n   - Early-career / narrowly focused: 3-5 codes\n   - Mid-career / multi-domain: 5-7 codes\n   - Senior / highly interdisciplinary: 7-10 codes\n   \n   This researcher appears to be ${careerStage}, so assign ${anzsrcCodeGuidance} ANZSRC codes.\n\n2. EVIDENCE REQUIREMENT:\n   - Every code MUST cite SPECIFIC evidence from the profile\n   - Reference actual publication titles, grant names, or biography text\n   - Do NOT assign codes based on vague similarity\n\n3. CONFIDENCE THRESHOLD:\n   - Only assign codes where confidence >= 0.70\n   - Rank codes by relevance (primary expertise first)\n\n4. HIERARCHICAL CONSTRAINTS:\n   - Don't assign both parent and child codes (e.g., not both 31 and 3106)\n   - Prefer most specific (6-digit) codes over broad codes\n   - Avoid redundant classifications (highly overlapping sibling codes)\n\n------------------------------------------------------------\nRESPONSE FORMAT (JSON only)\n------------------------------------------------------------\n{\n  \"standard_a\": {\n    \"taxonomy\": \"ANZSRC_FoR_2020\",\n    \"classifications\": [\n      {\n        \"code\": \"310601\",\n        \"name\": \"Biocatalysis and enzyme technology\",\n        \"confidence\": 0.92,\n        \"justification\": \"12 publications on lipase engineering including 'Title of specific paper'; ARC grant 'Enzyme optimisation for industrial bioprocessing'\",\n        \"evidence\": [\"Lipase immobilisation research\", \"ARC DP210101234\"]\n      }\n    ]\n  },\n  \"standard_b\": {\n    \"taxonomy\": \"OECD_FOS_2007\",\n    \"classifications\": [\n      {\n        \"code\": \"1.6\",\n        \"name\": \"Biological Sciences\",\n        \"confidence\": 0.88,\n        \"justification\": \"Broader domain alignment with biotechnology focus evident across publication portfolio\"\n      }\n    ]\n  },\n  \"career_stage_assessed\": \"${careerStage}\",\n  \"classification_depth_rationale\": \"Explanation of why N codes were assigned based on career breadth\",\n  \"reasoning\": \"Overall summary of how Standard A and Standard B classifications collectively represent the researcher's expertise\"\n}\n\n------------------------------------------------------------\nCRITICAL RULES\n------------------------------------------------------------\n1. Respond ONLY with valid JSON - no markdown, no code blocks, no extra text\n2. Standard A codes MUST be from the ANZSRC candidates listed above\n3. Standard B codes MUST be from the OECD FOS candidates listed above\n4. Every justification must reference SPECIFIC evidence (publication titles, grant names)\n5. Do NOT under-classify senior researchers - a 30-year career spanning multiple domains should have 7-10 codes\n6. Do NOT over-classify early-career researchers - limited evidence should result in 3-5 focused codes`;\n\n// ============================================================\n// RETURN OUTPUT\n// ============================================================\nreturn [{\n  json: {\n    // Pass through researcher data\n    asset_id: inputData.asset_id,\n    name: inputData.name,\n    orcid: inputData.orcid,\n    institution: inputData.institution,\n    qdrant_point_id: inputData.qdrant_point_id,\n    \n    // Dense view for downstream nodes\n    dense_view_text: inputData.dense_view_text,\n    \n    // Raw evidence (pass through for audit)\n    raw_evidence: inputData.raw_evidence,\n    enriched_context: inputData.enriched_context,\n    \n    // Research profile\n    research_domains: inputData.research_domains,\n    methodologies: inputData.methodologies,\n    research_themes: inputData.research_themes,\n    h_index: inputData.h_index,\n    career_stage: careerStage,\n    \n    // Data quality (pass through)\n    data_quality: inputData.data_quality,\n    \n    // Candidates for reference\n    field_candidates: anzsrcCandidates,\n    field_candidate_count: anzsrcCandidates.length,\n    fos_candidates: fosCandidates,\n    fos_candidate_count: fosCandidates.length,\n    \n    // Hierarchical search metadata\n    matched_groups: inputData.matched_groups,\n    retrieval_sources: inputData.retrieval_sources,\n    reranking: inputData.reranking,\n    \n    // LLM prompt\n    user_prompt: userPrompt,\n    \n    // Guidance used (for tracking/audit)\n    classification_guidance: {\n      career_stage: careerStage,\n      career_stage_description: careerStageDescription,\n      anzsrc_code_range: anzsrcCodeGuidance,\n      fos_code_range: fosCodeGuidance\n    },\n    \n    // Retry tracking\n    llm_retry_count: inputData.llm_retry_count || 0\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1424,
        288
      ],
      "id": "2db3824b-9bb0-4ad2-845e-7f3b92cf0153",
      "name": "Prepare Dual-Standard LLM Prompt"
    },
    {
      "parameters": {
        "jsCode": "// Node 2: Prepare Vector Search GROUPS\n// Purpose: Prepare data and request body for Qdrant vector similarity search\n\nconst inputData = $input.first().json;\n\n// Validate embedding vector\nif (!inputData.embedding_vector || inputData.embedding_vector.length !== 3072) {\n  throw new Error(`Invalid embedding vector. Expected 3072 dimensions, got ${inputData.embedding_vector?.length || 0}`);\n}\n\n// Prepare Qdrant request body\nconst qdrant_request_body = {\n  query: inputData.embedding_vector,\n  filter: {\n  must: [\n    {\n      key: \"level\",\n      match: {\n        value: \"field\"    \n      }\n    }\n  ]\n},\nlimit: 75,  \n  with_payload: true,\n  with_vector: false\n};\n\nreturn [{\n  json: {\n    // Researcher identification\n    asset_id: inputData.asset_id,\n    name: inputData.name,\n    qdrant_point_id: inputData.qdrant_point_id,\n    \n    // Research profile for LLM context later\n    research_domains: inputData.research_domains || [],\n    methodologies: inputData.methodologies || [],\n    research_themes: inputData.research_themes || [],\n    h_index: inputData.h_index,\n    total_citations: inputData.total_citations,\n    career_stage: inputData.career_stage,\n    \n    // Qdrant request body (ready to stringify)\n    qdrant_request_body: qdrant_request_body\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1664,
        -144
      ],
      "id": "876cee0c-ac77-4e3c-b7ff-f50aa164d030",
      "name": "Prepare Vector Search FIELDS"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.cohere.com/v2/rerank",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "cohereApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.cohere_request_body) }}",
        "options": {}
      },
      "id": "54336a36-ce47-4c68-9770-4de82be9c753",
      "name": "Cohere Rerank",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        208,
        288
      ],
      "credentials": {
        "openRouterApi": {
          "id": "1srwGILgkvMmHRRn",
          "name": "OpenRouter account"
        },
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        },
        "cohereApi": {
          "id": "r3yyDdVpi3CmVDjc",
          "name": "Cohere-API TrialKey"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Node: Prepare Cohere Request (FIXED)\nconst inputData = $input.first().json;\n\n// Build documents array using embedding_text for rich context\nconst documents = inputData.field_candidates.map(f => {\n  if (f.embedding_text) {\n    return f.embedding_text;\n  } else {\n    return `${f.code} - ${f.name}`;\n  }\n});\n\nconst richContextCount = inputData.field_candidates.filter(f => f.embedding_text).length;\nconsole.log(`Cohere request: ${documents.length} documents (${richContextCount} with rich context)`);\n\n// Build Cohere rerank request body\nconst cohereRequestBody = {\n  model: \"rerank-v3.5\",\n  query: inputData.dense_view_text,\n  documents: documents,\n  top_n: 25\n};\n\nreturn [{\n  json: {\n    // Pass through all researcher data explicitly\n    asset_id: inputData.asset_id,\n    name: inputData.name,\n    orcid: inputData.orcid,\n    institution: inputData.institution,\n    qdrant_point_id: inputData.qdrant_point_id,\n    research_domains: inputData.research_domains,\n    methodologies: inputData.methodologies,\n    research_themes: inputData.research_themes,\n    h_index: inputData.h_index,\n    career_stage: inputData.career_stage,\n    dense_view_text: inputData.dense_view_text,\n    embedding_vector: inputData.embedding_vector,\n    \n    // Field candidates\n    field_candidates: inputData.field_candidates,\n    field_codes: inputData.field_codes,\n    vector_candidate_count: inputData.vector_candidate_count,\n    \n    // Cohere request body\n    cohere_request_body: cohereRequestBody\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -80,
        288
      ],
      "id": "7842436c-8a4d-4258-8fc2-0fbb12c1276c",
      "name": "Prepare Cohere Request"
    },
    {
      "parameters": {
        "jsCode": "// Parse Cohere Rerank Results\nconst cohereResponse = $input.first().json;\nconst originalData = $('Parse Vector Search Results').first().json;\n\nconst fieldCandidates = originalData.field_candidates;\nconst rerankedResults = cohereResponse.results || [];\n\n// Map reranked indices back to original candidates\nconst rerankedCandidates = rerankedResults.map(result => ({\n  ...fieldCandidates[result.index],\n  rerank_score: result.relevance_score\n}));\n\nreturn [{\n  json: {\n    ...originalData,\n    field_candidates: rerankedCandidates,\n    field_candidate_count: rerankedCandidates.length,\n    reranking: {\n      applied: true,\n      model: 'rerank-v3.5',\n      original_count: fieldCandidates.length,\n      reranked_count: rerankedCandidates.length\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        416,
        288
      ],
      "id": "5148d1fd-540f-47d7-888f-1bccedfbb97c",
      "name": "Parse Cohere Rerank Results"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://3d3d355d-350c-4fd3-a844-17ca2599c7c0.europe-west3-0.gcp.cloud.qdrant.io/collections/standards_anzsrc1_for_2020/points/query",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "qdrantRestApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.qdrant_field_request) }}",
        "options": {}
      },
      "id": "8d7b0017-0a6f-4b56-81ab-c82985c1007a",
      "name": "Vector Search FIELDS",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        -560,
        288
      ],
      "credentials": {
        "openRouterApi": {
          "id": "1srwGILgkvMmHRRn",
          "name": "OpenRouter account"
        },
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        }
      }
    },
    {
      "parameters": {
        "options": {}
      },
      "type": "n8n-nodes-base.splitInBatches",
      "typeVersion": 3,
      "position": [
        -320,
        -384
      ],
      "id": "55b7dafe-2e49-4131-a301-06db6ea0c9d6",
      "name": "Loop Over Items"
    },
    {
      "parameters": {},
      "type": "n8n-nodes-base.noOp",
      "name": "Replace Me",
      "typeVersion": 1,
      "position": [
        1872,
        1152
      ],
      "id": "b24054d0-4320-4837-8fc1-5f926b73d175"
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// Handle Sparse Data Check\n// Version: v3.7.0\n// Fixed: Now checks correct paths for raw_evidence structure\n// ============================================================\n\nconst inputData = $input.first().json;\n\n// ============================================================\n// EXTRACT DATA FROM CORRECT PATHS (v3.7 structure)\n// ============================================================\nconst rawEvidence = inputData.raw_evidence || {};\nconst enrichedContext = inputData.enriched_context || {};\n\n// Get counts from correct locations\nconst publications = rawEvidence.publications || [];\nconst grants = rawEvidence.grants || [];\nconst biography = rawEvidence.biography || '';\nconst researchInterests = rawEvidence.research_interests || [];\n\nconst researchDomains = enrichedContext.research_domains || inputData.research_domains || [];\nconst themes = enrichedContext.themes || inputData.research_themes || [];\nconst methodologies = enrichedContext.methodologies || inputData.methodologies || [];\n\n// ============================================================\n// CALCULATE DATA QUALITY METRICS\n// ============================================================\nconst publicationCount = publications.length;\nconst grantCount = grants.length;\nconst biographyLength = biography.length;\nconst researchInterestCount = researchInterests.length;\nconst domainCount = researchDomains.length;\nconst themeCount = themes.length;\n\n// ============================================================\n// DETERMINE IF DATA IS SUFFICIENT FOR CLASSIFICATION\n// Per v3.7 spec: Need publications OR biography OR research_interests\n// ============================================================\nconst hasPublications = publicationCount >= 3;\nconst hasBiography = biographyLength >= 100;\nconst hasResearchInterests = researchInterestCount >= 3;\nconst hasDomains = domainCount >= 1;\nconst hasThemes = themeCount >= 1;\n\n// Sufficient if we have at least ONE strong evidence source\nconst hasSufficientEvidence = hasPublications || hasBiography || hasResearchInterests;\n\n// Also need some enriched context\nconst hasEnrichedContext = hasDomains || hasThemes;\n\n// Final determination\nconst isSufficient = hasSufficientEvidence && hasEnrichedContext;\nconst isSparse = !isSufficient;\n\n// ============================================================\n// BUILD DATA QUALITY OBJECT\n// ============================================================\nconst dataQuality = {\n  // Counts\n  publication_count: publicationCount,\n  grant_count: grantCount,\n  biography_length: biographyLength,\n  research_interest_count: researchInterestCount,\n  research_domains_count: domainCount,\n  research_themes_count: themeCount,\n  \n  // Flags\n  has_publications: hasPublications,\n  has_biography: hasBiography,\n  has_research_interests: hasResearchInterests,\n  has_domains: hasDomains,\n  has_themes: hasThemes,\n  \n  // Overall assessment\n  has_sufficient_evidence: hasSufficientEvidence,\n  has_enriched_context: hasEnrichedContext,\n  sufficient: isSufficient,\n  \n  // v3.7: Confidence penalty for missing fields\n  missing_fields: [],\n  confidence_penalty: 0\n};\n\n// Track missing fields for v3.7 penalty\nif (!hasPublications) dataQuality.missing_fields.push('publications');\nif (!hasBiography) dataQuality.missing_fields.push('biography');\nif (grantCount === 0) dataQuality.missing_fields.push('grants');\nif (!hasResearchInterests) dataQuality.missing_fields.push('research_interests');\n\n// Apply penalty if missing required fields but still classifiable\nif (isSufficient && dataQuality.missing_fields.length > 0) {\n  dataQuality.confidence_penalty = 0.10; // -10% per v3.7 spec\n  dataQuality.has_issue = true;\n}\n\n// ============================================================\n// LOG DECISION\n// ============================================================\nconsole.log(`\\n============================================================`);\nconsole.log(`üìä DATA QUALITY CHECK: ${inputData.name}`);\nconsole.log(`============================================================`);\nconsole.log(`   Publications:        ${publicationCount} ${hasPublications ? '‚úÖ' : '‚ö†Ô∏è'}`);\nconsole.log(`   Biography:           ${biographyLength} chars ${hasBiography ? '‚úÖ' : '‚ö†Ô∏è'}`);\nconsole.log(`   Research Interests:  ${researchInterestCount} ${hasResearchInterests ? '‚úÖ' : '‚ö†Ô∏è'}`);\nconsole.log(`   Grants:              ${grantCount}`);\nconsole.log(`   Research Domains:    ${domainCount} ${hasDomains ? '‚úÖ' : '‚ö†Ô∏è'}`);\nconsole.log(`   Themes:              ${themeCount} ${hasThemes ? '‚úÖ' : '‚ö†Ô∏è'}`);\nconsole.log(`   ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ`);\nconsole.log(`   Sufficient Evidence: ${hasSufficientEvidence ? 'YES ‚úÖ' : 'NO ‚ùå'}`);\nconsole.log(`   Enriched Context:    ${hasEnrichedContext ? 'YES ‚úÖ' : 'NO ‚ùå'}`);\nconsole.log(`   OVERALL:             ${isSufficient ? 'PROCEED TO CLASSIFICATION ‚úÖ' : 'ROUTE TO HITL ‚ùå'}`);\nconsole.log(`============================================================\\n`);\n\n// ============================================================\n// ROUTING DECISION\n// ============================================================\nif (isSparse) {\n  // Route to HITL - insufficient data for automated classification\n  return [{\n    json: {\n      ...inputData,\n      data_quality: dataQuality,\n      classification_skipped: true,\n      skip_reason: 'Insufficient data for automated classification',\n      routing_decision: 'SPARSE_DATA_HITL',\n      requires_hitl: true,\n      queue: 'human_review_queue',\n      confidence: 0,\n      routing_reason: `Sparse data: ${publicationCount} publications, ${domainCount} domains, ${themeCount} themes`\n    }\n  }];\n} else {\n  // Proceed to classification\n  return [{\n    json: {\n      ...inputData,\n      data_quality: dataQuality,\n      classification_skipped: false,\n      routing_decision: 'PROCEED_TO_CLASSIFICATION'\n    }\n  }];\n}"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -48,
        16
      ],
      "id": "cb943800-7db6-4280-9fce-6ba67eb077d4",
      "name": "Check Data Quality"
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "eaf1b00f-6064-48cb-862c-48270ad1671a",
              "leftValue": "={{ $json.classification_skipped }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        208,
        16
      ],
      "id": "1c7aa336-c6b8-4cf0-a6a5-0bd0a80c08d0",
      "name": "Handle Sparse Data"
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// Node: Prepare Sparse Update (Neo4j)\n// Purpose: Build Neo4j query to update sparse-data researcher status\n// ============================================================\n\nconst inputData = $input.first().json;\n\nreturn [{\n  json: {\n    // Pass through all existing data\n    ...inputData,\n    \n    // Neo4j update payload\n    neo4j_sparse_update: {\n      statement: `\n        MATCH (fat:FATObject {asset_id: $asset_id})\n        SET fat.status = 'pending_review',\n            fat.requires_hitl = true,\n            fat.hitl_reason = $hitl_reason,\n            fat.data_quality = $data_quality,\n            fat.routed_at = datetime()\n        RETURN fat.asset_id AS asset_id, \n               fat.name AS name, \n               fat.status AS status\n      `,\n      parameters: {\n        asset_id: inputData.asset_id,\n        hitl_reason: inputData.routing_reason || 'Sparse data - manual classification required',\n        data_quality: JSON.stringify(inputData.data_quality || {})\n      }\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        464,
        -256
      ],
      "id": "a3780988-f16a-4fb3-bd40-2b87fd7ae7d9",
      "name": "Update Neo4j Status (Sparse)"
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// Node: Prepare Sparse Queue Insert\n// Purpose: Build PostgreSQL payload for sparse-data HITL routing\n// ============================================================\n\nconst inputData = $input.first().json;\n\n// Generate UUID for queue entry\nconst generateUUID = () => {\n  return 'xxxxxxxx-xxxx-4xxx-yxxx-xxxxxxxxxxxx'.replace(/[xy]/g, function(c) {\n    const r = Math.random() * 16 | 0;\n    const v = c === 'x' ? r : (r & 0x3 | 0x8);\n    return v.toString(16);\n  });\n};\n\nconst queueEntryId = generateUUID();\n\n// Build PostgreSQL payload matching validation_queue schema\nconst postgresPayload = {\n  queue_entry_id: queueEntryId,\n  asset_id: inputData.asset_id,\n  queue: 'human_review_queue',\n  status: 'pending_review',\n  confidence: 0,\n  threshold_applied: 'SPARSE_DATA',\n  routing_reason: inputData.routing_reason || 'Sparse data - manual classification required',\n  \n  // Assessment flags\n  assessment_flags: {\n    data_quality: inputData.data_quality,\n    sparse_data: true\n  },\n  \n  // Escalation flags\n  escalation_flags: ['sparse_data_hitl'],\n  \n  // CRE fields (not applicable for sparse data, but include for schema consistency)\n  cre_blocking_failures: [],\n  cre_penalising_failures: [],\n  cre_requires_hitl: true,\n  blocked_by_cre: false,\n  \n  // HITL validation metadata\n  hitl_validation: null,\n  \n  // Workflow tracking\n  synced: false,\n  routed_at: new Date().toISOString(),\n  approved_at: null,\n  classification_version: 'v3.6.2',\n  routing_version: 'v3.5_sparse'\n};\n\nreturn [{\n  json: {\n    ...inputData,\n    queue_entry_id: queueEntryId,\n    postgres_payload: postgresPayload\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        1008,
        -256
      ],
      "id": "4bb54fbd-ad18-4729-b109-81a84dbc4d1d",
      "name": "Prepare Sparse Queue Insert"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://esgwrqcyhtzcsbepvqhc.supabase.co/rest/v1/validation_queue",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "supabaseApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "prefer",
              "value": "return=representation"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={ $json.postgres_payload }}",
        "options": {
          "timeout": 30000
        }
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1280,
        -256
      ],
      "id": "60d2015e-8e02-4e28-a8d6-0d06bc9e159f",
      "name": "Write to Validation Queue (Sparse)",
      "credentials": {
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        },
        "supabaseApi": {
          "id": "vTKATqGswB3PHE6S",
          "name": "Supabase account"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "eaf1b00f-6064-48cb-862c-48270ad1671a",
              "leftValue": "={{ $json.needs_retry }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -1376,
        608
      ],
      "id": "98eb008e-f706-4edb-ad12-0c83455f4261",
      "name": "Check Parse Success"
    },
    {
      "parameters": {
        "jsCode": "// Update FATObject status to classification_failed in Neo4j\nconst inputData = $input.first().json;\n\nreturn [{\n  json: {\n    ...inputData,\n    neo4j_failure_update: {\n      statement: `\n        MATCH (fat:FATObject {asset_id: $asset_id})\n        SET fat.status = 'classification_failed',\n            fat.classification_error = $error_message,\n            fat.classification_failed_at = datetime(),\n            fat.llm_retry_count = $retry_count\n        RETURN fat.asset_id, fat.status, fat.classification_error\n      `,\n      parameters: {\n        asset_id: inputData.asset_id,\n        error_message: inputData.failure_reason || inputData.parse_error || 'Unknown error',\n        retry_count: inputData.llm_retry_count || 0\n      }\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1568,
        992
      ],
      "id": "5582ba28-39eb-4959-a59f-26d29327d932",
      "name": "Prepare Failure Update (Neo4j)"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://8b9cbf46.databases.neo4j.io/db/neo4j/query/v2",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.neo4j_sparse_update }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        720,
        -256
      ],
      "id": "f6b27742-edcd-4e06-b3ca-c69a72777247",
      "name": "Execute Status Update to (Sparse Data)",
      "credentials": {
        "httpBasicAuth": {
          "id": "HximmqteOLptnTyu",
          "name": "Neo4j Gen 2"
        }
      }
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://8b9cbf46.databases.neo4j.io/db/neo4j/query/v2",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.neo4j_failure_update }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        -1280,
        992
      ],
      "id": "71152cdc-5381-4e80-afd1-1a88dfae07c4",
      "name": "Execute Status Update to (Sparse Data)1",
      "credentials": {
        "httpBasicAuth": {
          "id": "HximmqteOLptnTyu",
          "name": "Neo4j Gen 2"
        }
      }
    },
    {
      "parameters": {
        "conditions": {
          "options": {
            "caseSensitive": true,
            "leftValue": "",
            "typeValidation": "loose",
            "version": 2
          },
          "conditions": [
            {
              "id": "eaf1b00f-6064-48cb-862c-48270ad1671a",
              "leftValue": "={{ $json.classification_failed }}",
              "rightValue": true,
              "operator": {
                "type": "boolean",
                "operation": "equals"
              }
            }
          ],
          "combinator": "and"
        },
        "looseTypeValidation": true,
        "options": {}
      },
      "type": "n8n-nodes-base.if",
      "typeVersion": 2.2,
      "position": [
        -1088,
        624
      ],
      "id": "4e37c68c-8b7c-41b7-9786-406f663ee602",
      "name": "Classification Failed"
    },
    {
      "parameters": {
        "jsCode": "// Node: Prepare Vector Search GROUPS (Phase 2a)\n// v3.7: Hierarchical search - groups first, then fields within matched groups\n\nconst inputData = $input.first().json;\n\n// Validate embedding vector\nif (!inputData.embedding_vector || inputData.embedding_vector.length !== 3072) {\n  throw new Error(`Invalid embedding vector. Expected 3072 dimensions, got ${inputData.embedding_vector?.length || 0}`);\n}\n\n// Qdrant request for GROUP-level search (4-digit codes)\nconst qdrantGroupRequest = {\n  query: inputData.embedding_vector,\n  filter: {\n    must: [{\n      key: \"level\",\n      match: { value: \"group\" }\n    }]\n  },\n  limit: 35,\n  with_payload: true,\n  with_vector: false\n};\n\nreturn [{\n  json: {\n    asset_id: inputData.asset_id,\n    name: inputData.name,\n    orcid: inputData.orcid,\n    institution: inputData.institution,\n    qdrant_point_id: inputData.qdrant_point_id,\n    dense_view_text: inputData.dense_view_text,\n    raw_evidence: inputData.raw_evidence,\n    enriched_context: inputData.enriched_context,\n    career_stage: inputData.career_stage,\n    research_domains: inputData.research_domains,\n    methodologies: inputData.methodologies,\n    research_themes: inputData.research_themes,\n    h_index: inputData.h_index,\n    data_quality: inputData.data_quality,\n    embedding_vector: inputData.embedding_vector,\n    qdrant_group_request: qdrantGroupRequest\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1664,
        288
      ],
      "id": "03b2b4fb-1a4c-4e1f-8289-cd91615c6b45",
      "name": "Prepare Vector Search GROUPS"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://3d3d355d-350c-4fd3-a844-17ca2599c7c0.europe-west3-0.gcp.cloud.qdrant.io/collections/standards_anzsrc1_for_2020/points/query",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "qdrantRestApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.qdrant_group_request) }}",
        "options": {}
      },
      "id": "4c632d49-0c13-4a47-9d77-233f28068dcb",
      "name": "Vector Search GROUPS",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        -1440,
        288
      ],
      "credentials": {
        "openRouterApi": {
          "id": "1srwGILgkvMmHRRn",
          "name": "OpenRouter account"
        },
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// Parse Group Vector Search Results & Prepare Cohere Rerank\n// Phase 2a Step 3: Rerank top 35 groups to top 20\n\nconst qdrantResponse = $input.first().json;\nconst originalData = $('Prepare Vector Search GROUPS').first().json;\n\nconst responseData = Array.isArray(qdrantResponse) ? qdrantResponse[0] : qdrantResponse;\nconst points = responseData.result?.points || [];\n\nif (points.length === 0) {\n  console.log('‚ö†Ô∏è No groups found - falling back to flat field search');\n  \n  // Fallback: direct field search without group filtering\n  const fallbackFieldRequest = {\n    query: originalData.embedding_vector,\n    filter: {\n      must: [{\n        key: \"level\",\n        match: { value: \"field\" }\n      }]\n    },\n    limit: 75,\n    with_payload: true,\n    with_vector: false\n  };\n  \n  return [{\n    json: {\n      ...originalData,\n      group_candidates: [],\n      matched_group_numbers: [],\n      use_hierarchical_search: false,\n      fallback_reason: 'No group matches found',\n      qdrant_field_request: fallbackFieldRequest\n    }\n  }];\n}\n\n// Extract group candidates\nconst groupCandidates = points.map(point => ({\n  code: point.payload.code,\n  name: point.payload.name,\n  score: point.score,\n  embedding_text: point.payload.embedding_text || `${point.payload.code} - ${point.payload.name}`\n}));\n\nconsole.log(`‚úÖ Group Vector Search: Found ${groupCandidates.length} groups`);\nconsole.log(`   Top 5: ${groupCandidates.slice(0, 5).map(g => `${g.code} (${g.score.toFixed(3)})`).join(', ')}`);\n\n// Prepare Cohere rerank to get top 20 groups\nconst cohereGroupRequest = {\n  model: \"rerank-v3.5\",\n  query: originalData.dense_view_text,\n  documents: groupCandidates.map(g => g.embedding_text),\n  top_n: 20\n};\n\nreturn [{\n  json: {\n    ...originalData,\n    group_candidates: groupCandidates,\n    cohere_group_request: cohereGroupRequest,\n    use_hierarchical_search: true\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -1184,
        288
      ],
      "id": "d3154bfd-40c2-4ea8-a8f6-4b0b1617541f",
      "name": "Parse Group Results & Prepare Cohere"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://api.cohere.com/v2/rerank",
        "authentication": "predefinedCredentialType",
        "nodeCredentialType": "cohereApi",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ JSON.stringify($json.cohere_group_request) }}",
        "options": {}
      },
      "id": "05fa2920-b7e2-4cb6-9bd1-6e5094ea1a96",
      "name": "Cohere Rerank Groups",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.1,
      "position": [
        -976,
        288
      ],
      "credentials": {
        "openRouterApi": {
          "id": "1srwGILgkvMmHRRn",
          "name": "OpenRouter account"
        },
        "qdrantRestApi": {
          "id": "5kvIJD32UkQxRAis",
          "name": "Qdrant account"
        },
        "cohereApi": {
          "id": "r3yyDdVpi3CmVDjc",
          "name": "Cohere-API TrialKey"
        }
      }
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// Node: Extract Matched Groups\n// Version: v3.7.0\n// Purpose: Extract top 20 reranked groups and prepare field search with group filter\n// Phase 2a complete -> Phase 2b setup\n// ============================================================\n\nconst cohereResponse = $input.first().json;\nconst originalData = $('Parse Group Results & Prepare Cohere').first().json;\n\n// ============================================================\n// FALLBACK: Skip if not using hierarchical search\n// ============================================================\nif (!originalData.use_hierarchical_search) {\n  console.log('‚ö†Ô∏è Hierarchical search disabled, using fallback');\n  return [{ json: originalData }];\n}\n\n// ============================================================\n// PARSE COHERE RERANK RESULTS\n// ============================================================\nconst results = cohereResponse.results || [];\nconst groupCandidates = originalData.group_candidates || [];\n\nif (results.length === 0) {\n  console.log('‚ö†Ô∏è No rerank results, falling back to all groups');\n  return [{ json: originalData }];\n}\n\n// ============================================================\n// MAP COHERE INDICES BACK TO GROUP CODES\n// CRITICAL: Ensure codes are STRINGS for Qdrant filter\n// ============================================================\nconst matchedGroups = results.map(r => {\n  const group = groupCandidates[r.index];\n  \n  if (!group) {\n    console.log(`‚ö†Ô∏è No group found at index ${r.index}`);\n    return null;\n  }\n  \n  return {\n    code: String(group.code),           // ‚úÖ ENSURE STRING\n    name: group.name || 'Unknown',\n    vector_score: group.score || 0,\n    rerank_score: r.relevance_score || 0\n  };\n}).filter(g => g !== null);\n\n// ============================================================\n// EXTRACT GROUP NUMBERS (4-digit codes as STRINGS)\n// ============================================================\nconst matchedGroupNumbers = matchedGroups.map(g => String(g.code));\n\nconsole.log(`‚úÖ Reranked to ${matchedGroups.length} groups`);\nconsole.log(`   Top 5 groups: ${matchedGroupNumbers.slice(0, 5).join(', ')}`);\nconsole.log(`   Type check: ${typeof matchedGroupNumbers[0]}`);\n\n// ============================================================\n// BUILD QDRANT FIELD REQUEST WITH GROUP FILTER (Phase 2b)\n// ============================================================\nconst qdrantFieldRequest = {\n  query: originalData.embedding_vector,\n  filter: {\n    must: [\n      {\n        key: \"level\",\n        match: { value: \"field\" }\n      },\n      {\n        key: \"group_code\",\n        match: { any: matchedGroupNumbers }  // Strings for keyword index\n      }\n    ]\n  },\n  limit: 50,\n  with_payload: true,\n  with_vector: false\n};\n\n// ============================================================\n// OUTPUT: Pass through all data plus matched groups\n// ============================================================\nreturn [{\n  json: {\n    // Pass through original data\n    ...originalData,\n    \n    // Matched groups from reranking\n    matched_groups: matchedGroups,\n    matched_group_numbers: matchedGroupNumbers,\n    group_count: matchedGroups.length,\n    \n    // Qdrant request for field search\n    qdrant_field_request: qdrantFieldRequest,\n    \n    // Retrieval metadata\n    retrieval_sources: {\n      phase_2a_groups: matchedGroups.length,\n      phase_2a_method: 'vector_search + cohere_rerank',\n      phase_2a_top_group: matchedGroups[0]?.code || 'none'\n    }\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -752,
        288
      ],
      "id": "ec499422-6d5f-485a-94f4-47a52724b630",
      "name": "Extract Matched Groups"
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// Node: Parse Vector Search Results (FIELD Search)\n// Version: v3.7.0\n// Input: Qdrant vector search response for FIELDS\n// Output: Structured field candidates with embedding_text for LLM\n// ============================================================\n\nconst qdrantResponse = $input.first().json;\n\n// ============================================================\n// GET ORIGINAL DATA - Use correct node name!\n// ============================================================\nconst originalData = $('Extract Matched Groups').first().json;\n\n// Handle response structure\nconst responseData = Array.isArray(qdrantResponse) ? qdrantResponse[0] : qdrantResponse;\nconst points = responseData.result?.points || responseData.points || [];\n\nif (points.length === 0) {\n  console.log('‚ö†Ô∏è No field candidates found, check Qdrant query');\n  throw new Error(`No candidate standards found for asset_id: ${originalData.asset_id}`);\n}\n\n// ============================================================\n// EXTRACT FIELD CANDIDATES WITH SCORES AND EMBEDDING_TEXT\n// ============================================================\nconst fieldCandidates = points.map(point => ({\n  code: String(point.payload.code),\n  name: point.payload.name,\n  level: point.payload.level,\n  division_code: point.payload.division_code || String(point.payload.code).substring(0, 2),\n  group_code: point.payload.group_code || String(point.payload.code).substring(0, 4),\n  embedding_text: point.payload.embedding_text || null,\n  score: point.score\n}));\n\n// Get unique field codes\nconst fieldCodes = [...new Set(fieldCandidates.map(c => c.code))];\n\n// Log candidate pool\nconsole.log(`‚úÖ Field search returned ${points.length} candidates`);\nconsole.log(`   Fields with embedding_text: ${fieldCandidates.filter(f => f.embedding_text).length}`);\nconsole.log(`   Top 3 fields: ${fieldCandidates.slice(0, 3).map(f => f.code).join(', ')}`);\n\n// ============================================================\n// OUTPUT: Merge original data with field candidates\n// ============================================================\nreturn [{\n  json: {\n    // Pass through researcher data\n    asset_id: originalData.asset_id,\n    name: originalData.name,\n    orcid: originalData.orcid,\n    institution: originalData.institution,\n    qdrant_point_id: originalData.qdrant_point_id,\n    research_domains: originalData.research_domains || [],\n    methodologies: originalData.methodologies || [],\n    research_themes: originalData.research_themes || [],\n    h_index: originalData.h_index || 0,\n    career_stage: originalData.career_stage || 'unknown',\n    \n    // v3.7: raw_evidence and enriched_context\n    raw_evidence: originalData.raw_evidence || {},\n    enriched_context: originalData.enriched_context || {},\n    data_quality: originalData.data_quality || {},\n    \n    // Dense view text for LLM prompt\n    dense_view_text: originalData.dense_view_text || '',\n    \n    // Embedding for FOS search later\n    embedding_vector: originalData.embedding_vector,\n    \n    // FIELD candidate data (includes embedding_text)\n    field_candidates: fieldCandidates,\n    field_codes: fieldCodes,\n    vector_candidate_count: points.length,\n    \n    // Hierarchical search metadata\n    matched_groups: originalData.matched_groups || [],\n    matched_group_numbers: originalData.matched_group_numbers || [],\n    retrieval_sources: originalData.retrieval_sources || {}\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        -352,
        288
      ],
      "id": "cbf887e9-9503-47fc-870a-13740e6a750f",
      "name": "Parse Vector Search Results"
    },
    {
      "parameters": {
        "jsCode": "// ============================================================\n// Prepare Classification Signals for Neo4j (FIXED v3)\n// Version: v3.7.2\n// Fix: Uses MERGE to prevent duplicate signals\n// ============================================================\n\nconst inputData = $('Prepare Qdrant Payload').first().json;\nconst timestamp = new Date().toISOString();\nconst assetId = inputData.asset_id;\n\n// Build signals array\nconst signals = [];\n\n// ============================================================\n// 1. classification_completed (ALWAYS emitted)\n// ============================================================\nsignals.push({\n  signal_type: \"classification_completed\",\n  category: \"AssessmentSignal\",\n  target_entity: assetId,\n  timestamp: timestamp,\n  value: inputData.final_confidence,\n  reason: \"Classification completed successfully\",\n  metadata: JSON.stringify({\n    primary_code: inputData.classifications[0]?.code || null,\n    primary_label: inputData.classifications[0]?.name || null,\n    secondary_codes: inputData.classifications.slice(1).map(c => c.code),\n    code_count: inputData.classification_count,\n    standard_b_count: inputData.standard_b_count || 0,\n    raw_confidence: inputData.confidence_breakdown?.base_mean || null,\n    crosswalk_modifier: inputData.confidence_breakdown?.crosswalk_modifier || 0,\n    model_version: inputData.model || \"open-oss-120b\"\n  }),\n  workflow_id: \"OBJECT-3\",\n  workflow_version: \"v3.7\"\n});\n\n// ============================================================\n// 2. confidence_assessed (ALWAYS emitted)\n// ============================================================\nsignals.push({\n  signal_type: \"confidence_assessed\",\n  category: \"MeasurementSignal\",\n  target_entity: assetId,\n  timestamp: timestamp,\n  value: inputData.final_confidence,\n  reason: \"Confidence score calculated with modifiers\",\n  metadata: JSON.stringify({\n    raw_confidence: inputData.confidence_breakdown?.base_mean || null,\n    cf1_penalty: inputData.confidence_breakdown?.cf1_penalty || 0,\n    crosswalk_modifier: inputData.confidence_breakdown?.crosswalk_modifier || 0,\n    cre_penalty: inputData.confidence_breakdown?.cre_penalty || 0,\n    data_quality_penalty: inputData.confidence_breakdown?.data_quality_penalty || 0,\n    net_adjustment: inputData.confidence_breakdown?.net_adjustment || 0\n  }),\n  workflow_id: \"OBJECT-3\",\n  workflow_version: \"v3.7\"\n});\n\n// ============================================================\n// 3. data_quality_warning (CONDITIONAL)\n// ============================================================\nlet dataQuality = null;\ntry {\n  dataQuality = $('Handle Sparse Data').first().json.data_quality;\n} catch (e) {\n  dataQuality = inputData.data_quality || null;\n}\n\nif (dataQuality?.has_issue) {\n  signals.push({\n    signal_type: \"data_quality_warning\",\n    category: \"SystemSignal\",\n    target_entity: assetId,\n    timestamp: timestamp,\n    value: (dataQuality.confidence_penalty || 0) * -1,\n    reason: \"Dense view missing required fields for classification grounding\",\n    metadata: JSON.stringify({\n      missing_fields: dataQuality.missing_fields || [],\n      confidence_penalty_applied: dataQuality.confidence_penalty || 0,\n      flagged_for_review: true\n    }),\n    workflow_id: \"OBJECT-3\",\n    workflow_version: \"v3.7\"\n  });\n}\n\n// ============================================================\n// 4. threshold_breach (CONDITIONAL)\n// ============================================================\nconst AUTO_APPROVE_THRESHOLD = 0.85;\nconst FAIL_THRESHOLD = 0.60;\n\nif (inputData.final_confidence < AUTO_APPROVE_THRESHOLD) {\n  const routedTo = inputData.final_confidence >= FAIL_THRESHOLD \n    ? \"validation_queue\" \n    : \"reject\";\n  \n  signals.push({\n    signal_type: \"threshold_breach\",\n    category: \"AssessmentSignal\",\n    target_entity: assetId,\n    timestamp: timestamp,\n    value: inputData.final_confidence,\n    reason: \"Confidence score below auto-approval threshold\",\n    metadata: JSON.stringify({\n      threshold: AUTO_APPROVE_THRESHOLD,\n      actual_score: inputData.final_confidence,\n      gap: Math.round((inputData.final_confidence - AUTO_APPROVE_THRESHOLD) * 10000) / 10000,\n      routed_to: routedTo\n    }),\n    workflow_id: \"OBJECT-3\",\n    workflow_version: \"v3.7\"\n  });\n}\n\n// ============================================================\n// BUILD CYPHER USING MERGE (Prevents Duplicates)\n// ============================================================\nconst signalNeo4jPayload = {\n  statement: `\n    UNWIND $signals AS sig\n    \n    MATCH (e {asset_id: sig.target_entity})\n    \n    MERGE (s:Signal {\n      target_entity: sig.target_entity,\n      signal_type: sig.signal_type,\n      workflow_id: sig.workflow_id\n    })\n    ON CREATE SET\n      s.signal_id = sig.target_entity + ':' + sig.signal_type + ':' + sig.workflow_id,\n      s.category = sig.category,\n      s.timestamp = datetime(sig.timestamp),\n      s.value = sig.value,\n      s.reason = sig.reason,\n      s.metadata = sig.metadata,\n      s.workflow_version = sig.workflow_version\n    ON MATCH SET\n      s.timestamp = datetime(sig.timestamp),\n      s.value = sig.value,\n      s.reason = sig.reason,\n      s.metadata = sig.metadata,\n      s.workflow_version = sig.workflow_version\n    \n    MERGE (e)-[:HAS_SIGNAL]->(s)\n    \n    RETURN count(s) AS signals_merged\n  `,\n  parameters: {\n    signals: signals\n  }\n};\n\n// ============================================================\n// LOG SUMMARY\n// ============================================================\nconsole.log(`\\n============================================================`);\nconsole.log(`üì° SIGNAL EMISSION: ${inputData.name}`);\nconsole.log(`============================================================`);\nsignals.forEach(s => {\n  console.log(`   ${s.category === 'SystemSignal' ? '‚ö†Ô∏è' : '‚úÖ'} ${s.signal_type}`);\n});\nconsole.log(`   Total signals: ${signals.length}`);\nconsole.log(`============================================================\\n`);\n\n// ============================================================\n// RETURN OUTPUT\n// ============================================================\nreturn [{\n  json: {\n    ...inputData,\n    signals_emitted: signals,\n    signal_count: signals.length,\n    signal_neo4j_payload: signalNeo4jPayload\n  }\n}];"
      },
      "type": "n8n-nodes-base.code",
      "typeVersion": 2,
      "position": [
        320,
        896
      ],
      "id": "51265f01-7cbe-4d0c-96e7-2ed391c51cbb",
      "name": "Prepare Classification Signals"
    },
    {
      "parameters": {
        "method": "POST",
        "url": "https://8b9cbf46.databases.neo4j.io/db/neo4j/query/v2",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpBasicAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "specifyBody": "json",
        "jsonBody": "={{ $json.signal_neo4j_payload }}",
        "options": {}
      },
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        528,
        896
      ],
      "id": "68dc71e0-c797-4573-b95f-48a856ef9f25",
      "name": "Write Signals to Neo4j",
      "credentials": {
        "httpBasicAuth": {
          "id": "HximmqteOLptnTyu",
          "name": "Neo4j Gen 2"
        }
      }
    }
  ],
  "pinData": {
    "When clicking ‚ÄòExecute workflow‚Äô": [
      {
        "json": {}
      }
    ]
  },
  "connections": {
    "When clicking ‚ÄòExecute workflow‚Äô": {
      "main": [
        [
          {
            "node": "Prepare Fetch FATObjects",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch FATObjects": {
      "main": [
        [
          {
            "node": "Parse Neo4j Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Neo4j Response": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Fetch Embedding Vector": {
      "main": [
        [
          {
            "node": "Merge Embedding",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge Embedding": {
      "main": [
        [
          {
            "node": "Prepare Vector Search GROUPS",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Fetch FATObjects(Colin)": {
      "main": [
        []
      ]
    },
    "Parse LLM Response": {
      "main": [
        [
          {
            "node": "Check Parse Success",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Pass 2: LLM Enrichment": {
      "main": [
        [
          {
            "node": "Parse LLM Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculate Final Confidence": {
      "main": [
        [
          {
            "node": "Prepare Neo4j Write Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Neo4j Write Query": {
      "main": [
        [
          {
            "node": "Write to Neo4j",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Write to Neo4j": {
      "main": [
        [
          {
            "node": "Prepare Qdrant Payload",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Qdrant": {
      "main": [
        [
          {
            "node": "Prepare PostgreSQL Classification Log",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Qdrant Payload": {
      "main": [
        [
          {
            "node": "Update Qdrant",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Fetch FATObjects": {
      "main": [
        [
          {
            "node": "Fetch FATObjects",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Execute Status Update to Classifying": {
      "main": [
        [
          {
            "node": "Parse Status Update Response",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Status Update Response": {
      "main": [
        [
          {
            "node": "Fetch Embedding Vector",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Status Update to Classifying": {
      "main": [
        [
          {
            "node": "Execute Status Update to Classifying",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Crosswalk Assessment Query": {
      "main": [
        [
          {
            "node": "Execute Crosswalk Assessment",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Execute Crosswalk Assessment": {
      "main": [
        [
          {
            "node": "Calculate Crosswalk Alignment",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Calculate Crosswalk Alignment": {
      "main": [
        [
          {
            "node": "Prepare CRE Input",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Final Output": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare PostgreSQL Classification Log": {
      "main": [
        [
          {
            "node": "Store Crosswalk Metadata",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Store Crosswalk Metadata": {
      "main": [
        [
          {
            "node": "Prepare Classification Signals",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Execute CRE Constraint Query": {
      "main": [
        []
      ]
    },
    "ANZSRC Hierarchy Check": {
      "main": [
        [
          {
            "node": "Calculate Final Confidence",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "SYSTEM-2_CRE_Assessment": {
      "main": [
        [
          {
            "node": "Merge CRE Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Merge CRE Output": {
      "main": [
        [
          {
            "node": "ANZSRC Hierarchy Check",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare CRE Input": {
      "main": [
        [
          {
            "node": "SYSTEM-2_CRE_Assessment",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Pass 2: LLM Enrichment",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "Prepare FOS Vector Search": {
      "main": [
        [
          {
            "node": "Vector Search FOS (Qdrant)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse FOS Candidates": {
      "main": [
        [
          {
            "node": "Prepare Dual-Standard LLM Prompt",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Vector Search FOS (Qdrant)": {
      "main": [
        [
          {
            "node": "Parse FOS Candidates",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Vector Search FIELDS": {
      "main": [
        []
      ]
    },
    "Cohere Rerank": {
      "main": [
        [
          {
            "node": "Parse Cohere Rerank Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Cohere Request": {
      "main": [
        [
          {
            "node": "Cohere Rerank",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Cohere Rerank Results": {
      "main": [
        [
          {
            "node": "Prepare FOS Vector Search",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Vector Search FIELDS": {
      "main": [
        [
          {
            "node": "Parse Vector Search Results",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Dual-Standard LLM Prompt": {
      "main": [
        [
          {
            "node": "Pass 2: LLM Enrichment",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Loop Over Items": {
      "main": [
        [],
        [
          {
            "node": "Check Data Quality",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Replace Me": {
      "main": [
        []
      ]
    },
    "Check Data Quality": {
      "main": [
        [
          {
            "node": "Handle Sparse Data",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Handle Sparse Data": {
      "main": [
        [
          {
            "node": "Update Neo4j Status (Sparse)",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare Status Update to Classifying",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Update Neo4j Status (Sparse)": {
      "main": [
        [
          {
            "node": "Execute Status Update to (Sparse Data)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Sparse Queue Insert": {
      "main": [
        [
          {
            "node": "Write to Validation Queue (Sparse)",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Write to Validation Queue (Sparse)": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Check Parse Success": {
      "main": [
        [
          {
            "node": "Pass 2: LLM Enrichment",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Classification Failed",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Execute Status Update to (Sparse Data)": {
      "main": [
        [
          {
            "node": "Prepare Sparse Queue Insert",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Failure Update (Neo4j)": {
      "main": [
        [
          {
            "node": "Execute Status Update to (Sparse Data)1",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Execute Status Update to (Sparse Data)1": {
      "main": [
        [
          {
            "node": "Loop Over Items",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Classification Failed": {
      "main": [
        [
          {
            "node": "Prepare Failure Update (Neo4j)",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "Prepare Crosswalk Assessment Query",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Vector Search GROUPS": {
      "main": [
        [
          {
            "node": "Vector Search GROUPS",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Vector Search GROUPS": {
      "main": [
        [
          {
            "node": "Parse Group Results & Prepare Cohere",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Group Results & Prepare Cohere": {
      "main": [
        [
          {
            "node": "Cohere Rerank Groups",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Cohere Rerank Groups": {
      "main": [
        [
          {
            "node": "Extract Matched Groups",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Extract Matched Groups": {
      "main": [
        [
          {
            "node": "Vector Search FIELDS",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Parse Vector Search Results": {
      "main": [
        [
          {
            "node": "Prepare Cohere Request",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Prepare Classification Signals": {
      "main": [
        [
          {
            "node": "Write Signals to Neo4j",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Write Signals to Neo4j": {
      "main": [
        [
          {
            "node": "Final Output",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "versionId": "3374fc5b-6185-4a17-8fce-b60746c7e9d5",
  "meta": {
    "templateCredsSetupCompleted": true,
    "instanceId": "bc0e623ae1bb3524870487de3c7fa60f3a571019006cc26dd79ca981250a48aa"
  },
  "id": "SOeEAqm7luyOjRhx",
  "tags": [
    {
      "updatedAt": "2025-12-16T11:15:39.965Z",
      "createdAt": "2025-12-16T11:15:39.965Z",
      "id": "3qOz4Ic6lOIRKblO",
      "name": "Dual Standard"
    },
    {
      "updatedAt": "2025-12-18T01:54:55.218Z",
      "createdAt": "2025-12-18T01:54:55.218Z",
      "id": "XpmoqTfbBuwBUZCw",
      "name": "CRE"
    },
    {
      "updatedAt": "2025-12-18T01:45:03.480Z",
      "createdAt": "2025-12-18T01:45:03.480Z",
      "id": "zT0OLWLVBAVEOSHg",
      "name": "Crosswalk"
    }
  ]
}